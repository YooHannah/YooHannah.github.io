<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>My Little World</title>
  
  <subtitle>learn and share</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoohannah.github.io/"/>
  <updated>2024-11-27T12:23:43.696Z</updated>
  <id>http://yoohannah.github.io/</id>
  
  <author>
    <name>YooHannah</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一些基础知识</title>
    <link href="http://yoohannah.github.io/post/deepLearning/basicKnowledge.html"/>
    <id>http://yoohannah.github.io/post/deepLearning/basicKnowledge.html</id>
    <published>2024-11-27T09:10:37.000Z</published>
    <updated>2024-11-27T12:23:43.696Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习会什么会崛起"><a href="#深度学习会什么会崛起" class="headerlink" title="深度学习会什么会崛起"></a>深度学习会什么会崛起</h1><p>随着 数据量的增多，计算能力的提高以及算法的进步，使得深度学习的训练周期变短，可以快速进行迭代更新优化<br>从而用于工业生成</p><p>下面以二分类问题为例，复习一下相关的数学知识和概念</p><h1 id="损失函数和成本函数"><a href="#损失函数和成本函数" class="headerlink" title="损失函数和成本函数"></a>损失函数和成本函数</h1><p>重新理解一下<br>损失函数是一个训练数据的预测结果和实际值的差<br>成本函数是所有训练数据的损失函数的平均值<br><img src="/image/deepLearning/1.png" alt></p><h1 id="常见求导公式"><a href="#常见求导公式" class="headerlink" title="常见求导公式"></a>常见求导公式</h1><p>1.C’=0(C为常数)；<br>2.(Xn)’=nX(n-1) (n∈R)；<br>3.(sinX)’=cosX；<br>4.(cosX)’=-sinX；<br>5.(aX)’=aXIna （ln为自然对数）；<br>6.(logaX)’=1/(Xlna) (a&gt;0，且a≠1)；<br>7.(tanX)’=1/(cosX)2=(secX)2<br>8.(cotX)’=-1/(sinX)2=-(cscX)2<br>9.(secX)’=tanX secX；<br>10.(cscX)’=-cotX cscX；</p><h1 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h1><h2 id="向前传播"><a href="#向前传播" class="headerlink" title="向前传播"></a>向前传播</h2><p>计算成本函数<br><img src="/image/deepLearning/2.png" alt></p><h2 id="向后传播"><a href="#向后传播" class="headerlink" title="向后传播"></a>向后传播</h2><p>通过链式求导得到每一轮计算中参数的导数，从而用于进行梯度下降计算<br><img src="/image/deepLearning/3.png" alt></p><h1 id="梯度下降计算过程"><a href="#梯度下降计算过程" class="headerlink" title="梯度下降计算过程"></a>梯度下降计算过程</h1><p><img src="/image/deepLearning/4.png" alt><br><img src="/image/deepLearning/5.png" alt><br><img src="/image/deepLearning/6.png" alt><br><img src="/image/deepLearning/7.png" alt><br>Neural network programming guideline<br>Whenever possible, avoid explicit for-loops.<br>避免for-loops循环计算带来的算力损耗，使用向量对上面两次循环(训练数迭代和参数迭代)进行优化，最终只剩训练次数一次loop 循环<br><img src="/image/deepLearning/8.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;深度学习会什么会崛起&quot;&gt;&lt;a href=&quot;#深度学习会什么会崛起&quot; class=&quot;headerlink&quot; title=&quot;深度学习会什么会崛起&quot;&gt;&lt;/a&gt;深度学习会什么会崛起&lt;/h1&gt;&lt;p&gt;随着 数据量的增多，计算能力的提高以及算法的进步，使得深度学习的训练周期变短
      
    
    </summary>
    
    
      <category term="deepLearning" scheme="http://yoohannah.github.io/tags/deepLearning/"/>
    
  </entry>
  
  <entry>
    <title>数据清洗和转换</title>
    <link href="http://yoohannah.github.io/post/machineLearning/dataWash.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/dataWash.html</id>
    <published>2024-10-15T12:14:37.000Z</published>
    <updated>2024-11-27T09:37:11.852Z</updated>
    
    <content type="html"><![CDATA[<h1 id="常见数据错误形式"><a href="#常见数据错误形式" class="headerlink" title="常见数据错误形式"></a>常见数据错误形式</h1><ol><li>超出正常数据范围，值或者太大或者太小</li><li>不符合相关校验规则，比如数值类型只能是整形，货币单位应该是美元，但是出现了英镑</li><li>形式错误，比如日期格式错误，电话号码格式错误，不符合相关语法语义规范</li></ol><p><img src="/image/LLM/236.png" alt></p><p>对于这样的数据要进行去除清洗处理</p><h1 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h1><p>针对数值，图片，视频，文字不同输入类型，有不同转换方式<br><img src="/image/LLM/237.png" alt><br><img src="/image/LLM/238.png" alt><br><img src="/image/LLM/239.png" alt><br><img src="/image/LLM/240.png" alt><br><img src="/image/LLM/241.png" alt><br>小结</p><ol><li>数值类型转换就采用各种归一化的计算公式进行转换</li><li>图片，可以采用裁剪尺寸，下采样，压缩，白化处理</li><li>视频，可以采用截取关键片段，采样关键针降低数据处理陈本</li><li>文字，可以进行词干提取，词形还原以及token化处理<br><img src="/image/LLM/242.png" alt></li></ol><h1 id="mL-常见算法类型"><a href="#mL-常见算法类型" class="headerlink" title="mL 常见算法类型"></a>mL 常见算法类型</h1><p>监督，自监督，半监督，无监督，强化学习<br><img src="/image/LLM/243.png" alt><br><img src="/image/LLM/244.png" alt></p><h2 id="自监督相关概念"><a href="#自监督相关概念" class="headerlink" title="自监督相关概念"></a>自监督相关概念</h2><p><img src="/image/LLM/245.png" alt></p><h2 id="决策树相关注意点"><a href="#决策树相关注意点" class="headerlink" title="决策树相关注意点"></a>决策树相关注意点</h2><p><img src="/image/LLM/246.png" alt><br><img src="/image/LLM/247.png" alt><br><img src="/image/LLM/248.png" alt></p><h2 id="二分类评价指标"><a href="#二分类评价指标" class="headerlink" title="二分类评价指标"></a>二分类评价指标</h2><p><img src="/image/LLM/249.png" alt></p><h2 id="复杂度解释or解释"><a href="#复杂度解释or解释" class="headerlink" title="复杂度解释or解释"></a>复杂度解释or解释</h2><p><img src="/image/LLM/250.png" alt><br><img src="/image/LLM/251.png" alt><br><img src="/image/LLM/252.png" alt><br><img src="/image/LLM/253.png" alt><br><img src="/image/LLM/254.png" alt></p><p><a href="https://c.d2l.ai/stanford-cs329p/syllabus.html#data-i" target="_blank" rel="noopener">李沐机器学习ppt</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;常见数据错误形式&quot;&gt;&lt;a href=&quot;#常见数据错误形式&quot; class=&quot;headerlink&quot; title=&quot;常见数据错误形式&quot;&gt;&lt;/a&gt;常见数据错误形式&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;超出正常数据范围，值或者太大或者太小&lt;/li&gt;
&lt;li&gt;不符合相关校验规则，比如
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>数据标注</title>
    <link href="http://yoohannah.github.io/post/machineLearning/datalabel.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/datalabel.html</id>
    <published>2024-10-14T13:05:37.000Z</published>
    <updated>2024-11-27T09:37:11.853Z</updated>
    
    <content type="html"><![CDATA[<p>根据标注数据的目的(数据优化还是训练模型)，数据当前的标注情况以及预算情况<br>可以根据下面的流程进行数据标注<br><img src="/image/LLM/226.png" alt></p><h1 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h1><p>如果一开始有一部分数据可以进行监督学习训练，然后用未标记的数据进行测试，拿到测试结果，<br>根据测试结果准确性判断是否将当前未标记数据当做标记数据添加到下一轮的训练中<br><img src="/image/LLM/227.png" alt><br><img src="/image/LLM/228.png" alt><br>由于这里的工作是进行数据标注，所以可以使用较深的神经网络或者较贵的模型进行训练<br>以保证得到更准确的标注结果</p><h1 id="众包标注"><a href="#众包标注" class="headerlink" title="众包标注"></a>众包标注</h1><p>如果有足够的资金预算，可以将数据交给第三方进行标注，然后将标注结果进行汇总<br><img src="/image/LLM/229.png" alt><br>但要面临如何降低标注门槛，标注质量，价格昂贵，标注人员不稳定等问题<br><img src="/image/LLM/230.png" alt></p><h2 id="主动学习"><a href="#主动学习" class="headerlink" title="主动学习"></a>主动学习</h2><p>只将训练结果最不确定的数据，或者最难标记的数据进行人工标注，然后用多个模型投票保证标记准确度<br><img src="/image/LLM/231.png" alt><br>通常与半监督学习结合使用<br><img src="/image/LLM/232.png" alt></p><h2 id="质量控制"><a href="#质量控制" class="headerlink" title="质量控制"></a>质量控制</h2><p>防止标错或者范围有问题，可以选择将一个数据发给多个标注人员进行标注，然后根据标注结果进行投票<br>但这样做会导致标注成本增加<br>降低成本的方法可以是，<br>一是从结果角度思考，先让模型进行推测，如果人工标注与模型推测结果相差较大，则将数据发给多个标注人员进行标注<br>否则停止任务发送，减少成本；或者发送的前几个人标记结果都一样，就停止发送更多人进行标记<br>二是从人的角度思考，先给一些有确定标注的数据给标记人员进行标注，如果标注结果与确定标注相差结果较大，说明标注人员能力有问题，进行人员更换<br><img src="/image/LLM/233.png" alt></p><h2 id="弱监督学习"><a href="#弱监督学习" class="headerlink" title="弱监督学习"></a>弱监督学习</h2><p>使用启发式规则通过数据编程得到一些有噪音的标注<br>通过半自动化的方式生成准确度弱于人工标记，但足以进行模型训练的标注<br>通过根据数据特征的一系列判断(启发式规则)进行投票，然后将投票结果进行阈值比较，从而判断属于哪个分类标签<br><img src="/image/LLM/233.png" alt></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>三种常见数据标注方式</p><ol><li>半监督学习</li><li>众包标注</li><li>弱监督学习<br>对于没有标记的数据也可以用无监督或者自监督学习进行训练<br><img src="/image/LLM/233.png" alt></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;根据标注数据的目的(数据优化还是训练模型)，数据当前的标注情况以及预算情况&lt;br&gt;可以根据下面的流程进行数据标注&lt;br&gt;&lt;img src=&quot;/image/LLM/226.png&quot; alt&gt;&lt;/p&gt;
&lt;h1 id=&quot;半监督学习&quot;&gt;&lt;a href=&quot;#半监督学习&quot; class=
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>强化学习</title>
    <link href="http://yoohannah.github.io/post/machineLearning/ReinforcementLearning.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/ReinforcementLearning.html</id>
    <published>2024-10-07T06:34:37.000Z</published>
    <updated>2024-11-27T09:37:11.850Z</updated>
    
    <content type="html"><![CDATA[<p>强化学习的主要思想不是告诉算法每个输入的正确输出是什么<br>而是指定一个奖励函数，告诉它什么时候做的好，什么时候做的不好<br>算法的工作是自动找出如何选择好的动作</p><p><img src="/image/LLM/202.png" alt></p><h1 id="一些概念"><a href="#一些概念" class="headerlink" title="一些概念"></a>一些概念</h1><p>以火星探测器为例，在其决定路线的过程中产生的几个概念</p><ol><li>S ： 当前状态</li><li>a : 动作</li><li>S’ : 下一个状态</li><li>R : 奖励函数</li><li><p>teminal state : 终止状态<br><img src="/image/LLM/203.png" alt><br>每种路线回报通过计算路上每一步奖励乘以折现系数加和得到<br><img src="/image/LLM/204.png" alt></p></li><li><p>policy : 策略函数，根据当前的状态选择可以获得最大收益的动作</p></li></ol><p>A policy is a function π（s）= a  mapping from states to actions, that tells you what action a to take in a given state s.</p><p>The goal of reinforcement learning ===&gt;<br>Find a policy 5 that tells you what action (a = 5(s)) to take in every state (s) so as to maximize the return.</p><p><img src="/image/LLM/205.png" alt></p><h1 id="马尔科夫决策过程"><a href="#马尔科夫决策过程" class="headerlink" title="马尔科夫决策过程"></a>马尔科夫决策过程</h1><p>未来只取决于当前的名称，而不是到达当前状态之前可能发生的任何事情</p><p><img src="/image/LLM/206.png" alt></p><h1 id="状态动作回报函数-Q"><a href="#状态动作回报函数-Q" class="headerlink" title="状态动作回报函数 Q"></a>状态动作回报函数 Q</h1><p>当前状态下执行一次函数能够得到的最大回报值<br>如果能够找到最大回报值也就能知道接下来应该用什么动作</p><p><img src="/image/LLM/207.png" alt></p><p><img src="/image/LLM/208.png" alt></p><h1 id="贝尔曼公式"><a href="#贝尔曼公式" class="headerlink" title="贝尔曼公式"></a>贝尔曼公式</h1><p><img src="/image/LLM/209.png" alt><br><img src="/image/LLM/210.png" alt><br><img src="/image/LLM/211.png" alt></p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>面对环境随机的情况，动作实际执行过程可能存在多个可能路线，导致每次得到的最大回报值不同，因此计算当前状态最大收益时取所有路线情况的平均值进行计算<br>即使用期望回报值进行计算<br><img src="/image/LLM/212.png" alt><br><img src="/image/LLM/213.png" alt></p><h1 id="DQN-算法"><a href="#DQN-算法" class="headerlink" title="DQN 算法"></a>DQN 算法</h1><p>D: deep learning<br>Q: Q function<br>N: Network</p><p>对于连续状态值的情况，使用神经网络训练Q函数进行深度强化学习<br><img src="/image/LLM/214.png" alt><br><img src="/image/LLM/215.png" alt><br><img src="/image/LLM/216.png" alt><br>By using experience replay we avoid problematic correlations, oscillations and instabilities. In addition, experience replay also allows the agent to potentially use the same experience in multiple weight updates, which increases data efficiency.<br>通过使用经验重放，我们可以避免有问题的相关性、振荡和不稳定性。此外，经验重放还允许代理在多次权重更新中使用相同的经验，从而提高数据效率。</p><h2 id="优化-1"><a href="#优化-1" class="headerlink" title="优化"></a>优化</h2><h3 id="优化神经网络结构"><a href="#优化神经网络结构" class="headerlink" title="优化神经网络结构"></a>优化神经网络结构</h3><p>上面将s和a作为X 同时参与训练，最终只会得到一个动作a最大回报函数值,需要进行多次运算<br>如果仅将s作为输入，输出层产生多个a的回报值，就可以根据回报值大小选择相应的动作</p><p><img src="/image/LLM/217.png" alt><br><img src="/image/LLM/218.png" alt></p><h3 id="epsilon-greedy-policy"><a href="#epsilon-greedy-policy" class="headerlink" title="epsilon-greedy policy"></a>epsilon-greedy policy</h3><p>选择action 过程中，如果一直按Q值最大原则选择action,万一初始值特别小无法开启我们想要的第一步程序，就会导致无法进行后续的action<br>epsilon-greedy policy 方案就是找一个合适的阈值epsilon，比如说0.05,<br>95%的时间选择最大Q值action (贪婪剥削策略)<br>5%的时间选择随机选择action（探索策略）<br>这样就可以避免选到固定不符合预期的action,开放一定的窗口有可能选到其他的action<br>epsilon 大小 类似于梯度，随训练过程进行会逐渐变小，变小的过程，模型也就学会了如何选择更有可能选择符合预期的action</p><p><img src="/image/LLM/219.png" alt></p><h3 id="小批量"><a href="#小批量" class="headerlink" title="小批量"></a>小批量</h3><p>训练数据如果非常庞大，在训练过程中可能会造成时间消耗，为了提高训练速度，可以采用小批量的方式进行<br>将训练数据分成多个批次，每次迭代用不同批次数据，虽然梯度会比较嘈杂，但还是会朝着梯度下降的方向进行<br><img src="/image/LLM/220.png" alt><br><img src="/image/LLM/221.png" alt><br><img src="/image/LLM/222.png" alt><br><img src="/image/LLM/223.png" alt></p><h3 id="软更新"><a href="#软更新" class="headerlink" title="软更新"></a>软更新</h3><p>在更新参数过程中，每次按比例更新参数，每次仅更新部分比例的参数，可以使强化学习更好的收敛<br><img src="/image/LLM/224.png" alt></p><h1 id="强化学习的一些限制"><a href="#强化学习的一些限制" class="headerlink" title="强化学习的一些限制"></a>强化学习的一些限制</h1><p><img src="/image/LLM/225.png" alt></p><p><a href="https://github.com/kaieye/2022-Machine-Learning-Specialization/blob/main/Unsupervised%20learning%20recommenders%20reinforcement%20learning/week3/Practice%20Lab-Reinforcement%20Learning/C3_W3_A1_Assignment.ipynb" target="_blank" rel="noopener">实验练习</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;强化学习的主要思想不是告诉算法每个输入的正确输出是什么&lt;br&gt;而是指定一个奖励函数，告诉它什么时候做的好，什么时候做的不好&lt;br&gt;算法的工作是自动找出如何选择好的动作&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/image/LLM/202.png&quot; alt&gt;&lt;/p&gt;
&lt;h1 id=
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统</title>
    <link href="http://yoohannah.github.io/post/machineLearning/RecommenderSystem.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/RecommenderSystem.html</id>
    <published>2024-10-05T23:10:37.000Z</published>
    <updated>2024-11-27T09:37:11.849Z</updated>
    
    <content type="html"><![CDATA[<p>下面以根据电影评分推荐电影为例，介绍推荐系统的开发过程</p><h1 id="思路整理"><a href="#思路整理" class="headerlink" title="思路整理"></a>思路整理</h1><p>根据电影的特征，用户对每个电影都会有一个评分(0-5分)，比如电影A的评分是5分，电影B的评分是4分，电影C的评分是3分<br>一般情况下，用户对某电影评分越高，说明后续对该类型电影的青睐度越高，对于系统来说越值得推荐给用户<br>即系统需要预测用户对某个电影X的评分，从而决定是否推荐给用户<br>系统需要依赖的数据是电影的特征数据（X）和以往用户对电影的评分数据(Y)<br>根据二者的关系，计算出相关的算法参数<br>当有需要预测一个电影评分的时候，输入待评分电影特征即可得到评分，然后根据阈值判断是否推荐给用户<br>下面是对一个观众的电影评分预测过程<br><img src="/image/LLM/179.png" alt><br>对应的成本函数<br><img src="/image/LLM/180.png" alt><br>如果训练集有多个用户的评分数据，拿到所有用户的参数后加合，就可以预测大众用户对某个电影的整体评分情况<br><img src="/image/LLM/181.png" alt></p><h1 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h1><p>对于电影的评分，一开始不能确定使用电影的哪些特征，协同过滤算法将输入，电影的特征X， 也看做是一个参数参与成本函数的计算<br>从而利用梯度下降过程找到合适的参数和特征值</p><h2 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h2><ol><li>已知多个人对一部电影的评分和相关参数，可以反推出X 的 情况<br><img src="/image/LLM/182.png" alt></li><li>如果现在已知多个人对一部电影的评分和相关参数，可以对电影特征X进行成本函数计算<br>加和之后可以对多个电影的特征进行预测<br><img src="/image/LLM/183.png" alt></li><li>观察成本函数的公式，现在加和参数和特征的成本函数，<br><img src="/image/LLM/185.png" alt><br><img src="/image/LLM/184.png" alt></li><li>可以发现， 梯度下降过程，可以同时找出多个人对电影评分参数和对多部电影的特征值推测<br><img src="/image/LLM/186.png" alt></li></ol><p>协同在这里的体现在于多个用户对一部电影进行了评价，通过合作得到了对电影的整体评价，同时可以预测出能够代表这部电影的特征值<br>反过来，可以预测尚未对同一部电影进行评分的其他用户的评分<br>即从多个用户收集数据，然后预测其他用户的评分</p><h1 id="线性回归转向二进制分类"><a href="#线性回归转向二进制分类" class="headerlink" title="线性回归转向二进制分类"></a>线性回归转向二进制分类</h1><p>基于线性回归的推荐系统适合于上面评分有连续值的推测，基于上述思路，将评分结果通过逻辑函数转成二进制结果<br>即可实现二进制分类问题的预测<br><img src="/image/LLM/187.png" alt><br><img src="/image/LLM/188.png" alt><br><img src="/image/LLM/189.png" alt></p><h1 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h1><h2 id="均值归一化"><a href="#均值归一化" class="headerlink" title="均值归一化"></a>均值归一化</h2><p>对于尚未对电影作为任何评价的用户，如果参数为0，那么预测的评分结果为0，会极大影响推荐的准确性<br>因此，先对多用户评分计算均值，然后对所有用户的评分减去均值，得到新的评分，在新的评分上进行参数获取<br>进行评分预测的时候再把均值加回来，这样即使参数为0，预测的评分值也是之前评分的均值，对整体评分meian值不会有影响<br><img src="/image/LLM/190.png" alt></p><h2 id="如何找到相似的推荐"><a href="#如何找到相似的推荐" class="headerlink" title="如何找到相似的推荐"></a>如何找到相似的推荐</h2><p>找到与当前item 距离最近的其他item<br><img src="/image/LLM/191.png" alt></p><h2 id="协同过滤的限制"><a href="#协同过滤的限制" class="headerlink" title="协同过滤的限制"></a>协同过滤的限制</h2><ol><li>对冷启动问题不友好</li><li>不能直接获取到有价值的特征数据，可能是关于观众或者电影的片面的信息，只能从这些信息上推测用户的爱好<br><img src="/image/LLM/192.png" alt></li></ol><h1 id="基于内容的推荐算法"><a href="#基于内容的推荐算法" class="headerlink" title="基于内容的推荐算法"></a>基于内容的推荐算法</h1><p>对比基于协同过滤的推荐算法(根据用户对相似item的评分进行推荐)<br>基于内容的推荐算法同时基于用户和item的特征，通过计算item 和用户的匹配度，来判断用户是否对该item感兴趣<br><img src="/image/LLM/193.png" alt></p><h2 id="主要思路"><a href="#主要思路" class="headerlink" title="主要思路"></a>主要思路</h2><p>利用神经网络从用户特征和item 特征中提取n 个特征，计算二者的点积从而判断用户是否对item感兴趣，是否要推荐给用户<br><img src="/image/LLM/194.png" alt><br><img src="/image/LLM/195.png" alt><br><img src="/image/LLM/196.png" alt><br><img src="/image/LLM/197.png" alt><br><img src="/image/LLM/198.png" alt></p><h1 id="从大目录中进行推荐"><a href="#从大目录中进行推荐" class="headerlink" title="从大目录中进行推荐"></a>从大目录中进行推荐</h1><ol><li><p>进行检索，找出候选列表<br>但是检索过程需要注意，通过对更多的项目进行检索可以得到更好的结果但是检索的速度回变慢，<br>为了分析优化权衡二者，可以实施离线实验观察新增的检索项是否增加了检索结果的相关性</p></li><li><p>对候选列表进行fine-tune排序找出得分最高的item给用户</p></li></ol><p><img src="/image/LLM/199.png" alt><br><img src="/image/LLM/200.png" alt><br><img src="/image/LLM/201.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;下面以根据电影评分推荐电影为例，介绍推荐系统的开发过程&lt;/p&gt;
&lt;h1 id=&quot;思路整理&quot;&gt;&lt;a href=&quot;#思路整理&quot; class=&quot;headerlink&quot; title=&quot;思路整理&quot;&gt;&lt;/a&gt;思路整理&lt;/h1&gt;&lt;p&gt;根据电影的特征，用户对每个电影都会有一个评分(0-5分
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>异常检测</title>
    <link href="http://yoohannah.github.io/post/machineLearning/abnormalTest.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/abnormalTest.html</id>
    <published>2024-10-05T10:50:37.000Z</published>
    <updated>2024-11-27T09:37:11.850Z</updated>
    
    <content type="html"><![CDATA[<h1 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h1><p>异常检测是机器学习中一个重要的概念，它是指在数据中检测出不符合预期的数据点，以便及时发现和处理异常情况。</p><h2 id="检测方法：密度估计"><a href="#检测方法：密度估计" class="headerlink" title="检测方法：密度估计"></a>检测方法：密度估计</h2><p>密度估计是异常检测中的一种方法，它通过计算数据的密度分布来识别异常数据点。<br>通过将特征值的可能性进行乘积计算，得到数据的密度，然后跟阈值进行比较，判断当前数据是否正常。<br><img src="/image/LLM/164.png" alt><br><img src="/image/LLM/169.png" alt><br><img src="/image/LLM/165.png" alt></p><h1 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h1><p>高斯分布的位置受数据集的平均值𝜇和方差𝜎^2 决定<br><img src="/image/LLM/166.png" alt><br>𝜇 决定钟形最高点在x轴上的位置<br>𝜎^2 决定钟形的宽度，因为整个钟形面积为1，所以，如果𝜎^2 变小，那个整个钟形会变得很高<br><img src="/image/LLM/167.png" alt></p><p><img src="/image/LLM/168.png" alt></p><h1 id="异常检测算法步骤"><a href="#异常检测算法步骤" class="headerlink" title="异常检测算法步骤"></a>异常检测算法步骤</h1><ol><li>在训练数据中选择你认为可能会引起异常的数据的n个特征值</li><li>计算各个特征值的平均值𝜇和方差𝜎^2</li><li>计算每个特征值的密度，如果密度小于阈值，则认为是异常数据</li></ol><p><img src="/image/LLM/170.png" alt></p><h1 id="开发过程中如何评估异常检测系统"><a href="#开发过程中如何评估异常检测系统" class="headerlink" title="开发过程中如何评估异常检测系统"></a>开发过程中如何评估异常检测系统</h1><p>通常采用实数评估方案，就是可以用一个具体的数值小小来衡量算法的好坏<br>假设训练数据中的数据都是正常的，存在标签0<br>在交叉验证和测试数据中，存在少量异常数据，标签为1<br>测试算法好坏的标准就是能否将异常数据识别出来<br>如果是特别少量的异常数据，可以仅通过交叉验证来评估测试好坏<br>从而决定合适的阈值大小<br><img src="/image/LLM/171.png" alt><br><img src="/image/LLM/172.png" alt><br>另外的评估方法可参考<a href>二分类错误度量</a><br>相关的衡量指标，真假值，精确率，召回率，F1 score等<br><img src="/image/LLM/173.png" alt></p><h1 id="如何选择异常检测算法和监督学习"><a href="#如何选择异常检测算法和监督学习" class="headerlink" title="如何选择异常检测算法和监督学习"></a>如何选择异常检测算法和监督学习</h1><p>异常检测算法适用于</p><ol><li>正常数据少量但是有大量异常数据</li><li>异常的特征值是未知的，且是多样的</li></ol><p>监督学习算法适用于</p><ol><li>存在大量异常和正常数据</li><li>有足够数据告诉算法什么是正常的数据，什么是异常的数据<br>将来出现的异常数据很可能是之前训练集中出现过的异常数据</li></ol><p><img src="/image/LLM/174.png" alt></p><p><img src="/image/LLM/175.png" alt></p><h1 id="如何选择要使用的特征"><a href="#如何选择要使用的特征" class="headerlink" title="如何选择要使用的特征"></a>如何选择要使用的特征</h1><ol><li><p>选择符合高斯分布的特征，如果不能拟合高斯分布，可以通过取对数，开方等方式进行特殊处理后进行拟合<br>但要注意，训练数据如果有对特征值进行特殊处理，那么交叉验证集合测试集也要进行相同的处理<br><img src="/image/LLM/176.png" alt></p></li><li><p>对于误判的异常数据，可以通过增加特征值来进行弥补，保证数据在新加的特征值上存在异常大或者异常小的数据</p></li></ol><p><img src="/image/LLM/177.png" alt></p><ol start="3"><li>可以在已有的原始特征值基础上创造新的特征值参与运算<br><img src="/image/LLM/178.png" alt></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;异常检测&quot;&gt;&lt;a href=&quot;#异常检测&quot; class=&quot;headerlink&quot; title=&quot;异常检测&quot;&gt;&lt;/a&gt;异常检测&lt;/h1&gt;&lt;p&gt;异常检测是机器学习中一个重要的概念，它是指在数据中检测出不符合预期的数据点，以便及时发现和处理异常情况。&lt;/p&gt;
&lt;h2 i
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>Kmeans 聚类算法</title>
    <link href="http://yoohannah.github.io/post/machineLearning/Kmeans.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/Kmeans.html</id>
    <published>2024-10-02T16:37:37.000Z</published>
    <updated>2024-11-27T09:37:11.848Z</updated>
    
    <content type="html"><![CDATA[<p>无监督学习算法一</p><h1 id="什么是聚类"><a href="#什么是聚类" class="headerlink" title="什么是聚类"></a>什么是聚类</h1><p>将输入数据分成多个类别，每个类别包含一组相似的数据点的过程就是聚类，分好的类被称为cluster</p><h1 id="聚类算法k-means处理过程"><a href="#聚类算法k-means处理过程" class="headerlink" title="聚类算法k-means处理过程"></a>聚类算法k-means处理过程</h1><ol><li>随机选择k个点作为初始的中心点, 计算每个点到中心点的距离，将每个点分配到距离最近的中心点所属的类别中</li><li>计算每个类别的中心点(平均值)，并更新中心点，重复步骤1</li><li>直到中心点不再变化，或者达到最大迭代次数</li></ol><h2 id="具体实现-伪代码"><a href="#具体实现-伪代码" class="headerlink" title="具体实现(伪代码)"></a>具体实现(伪代码)</h2><p><img src="/image/LLM/157.png" alt><br><img src="/image/LLM/158.png" alt></p><h2 id="成本函数"><a href="#成本函数" class="headerlink" title="成本函数"></a>成本函数</h2><p><img src="/image/LLM/159.png" alt><br><img src="/image/LLM/160.png" alt></p><h2 id="如何初始化中心点"><a href="#如何初始化中心点" class="headerlink" title="如何初始化中心点"></a>如何初始化中心点</h2><p>随机选择k个点作为初始的中心点（k小于m），计算最终中心点和损失函数<br>重复N次，选择损失函数最小的中心点作为最终的中心点<br><img src="/image/LLM/161.png" alt></p><h2 id="如何选择K的数量"><a href="#如何选择K的数量" class="headerlink" title="如何选择K的数量"></a>如何选择K的数量</h2><p>取决后续如何使用分类好的集群数据<br><img src="/image/LLM/163.png" alt><br><img src="/image/LLM/162.png" alt></p><p><a href="https://github.com/kaieye/2022-Machine-Learning-Specialization/blob/main/Unsupervised%20learning%20recommenders%20reinforcement%20learning/week1/2%20Practice%20Lab1/C3_W1_KMeans_Assignment.ipynb" target="_blank" rel="noopener">压缩图像应用</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;无监督学习算法一&lt;/p&gt;
&lt;h1 id=&quot;什么是聚类&quot;&gt;&lt;a href=&quot;#什么是聚类&quot; class=&quot;headerlink&quot; title=&quot;什么是聚类&quot;&gt;&lt;/a&gt;什么是聚类&lt;/h1&gt;&lt;p&gt;将输入数据分成多个类别，每个类别包含一组相似的数据点的过程就是聚类，分好的类被称为c
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>决策树模型</title>
    <link href="http://yoohannah.github.io/post/machineLearning/decisionTreeModel.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/decisionTreeModel.html</id>
    <published>2024-09-30T07:31:37.000Z</published>
    <updated>2024-11-27T09:37:11.853Z</updated>
    
    <content type="html"><![CDATA[<p>决策树模型是通过计算特征纯度后，选取最大纯度值的特征作为决策节点，<br>将数据根据是否符合当前特征节点一份为二，再根据特征纯度，继续划分，<br>最后根据停止划分规则进行数据分类或推测的模型</p><p><img src="/image/LLM/136.png" alt></p><h1 id="创建过程"><a href="#创建过程" class="headerlink" title="创建过程"></a>创建过程</h1><p>决策树创建过程需要考虑两件事</p><ol><li><p>在每个节点上如果选择根据什么特征进行数据分类<br>Maximize purity<br>如果一个特征在把数据分成两组之后，使分组后的数据能够最大程度的趋于同一类，那么这个特征就是纯度高的特征,<br>即 如果这个特征能够直接决定数据属于哪个分类的程度越高，纯度就越高<br>比如用DNA特征判断猫狗分类比用耳朵是尖的还是软的更直接，DNA特征就是最大纯度的特征<br><img src="/image/LLM/137.png" alt></p></li><li><p>什么时候停止数据分类<br>a. 当一个节点里面的数据都属于同一类的时候<br>b. 到达树的深度最大值的时候，树越深，过拟合越有可能，计算成本越高<br>c. 当特征纯度(熵)低于某个阈值的时候<br>d. 当节点里的数据个数低于某个阈值的时候</p></li></ol><p><img src="/image/LLM/138.png" alt></p><h2 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h2><p>可以理解为数据的混乱程度，如果数据特别混乱，则值越大，返回数据如果种类单一，则值越小，趋近0<br>这里用熵来计算特征的非纯度或者较杂质程度，<br>如果根据某个特征分类后的数据的熵 越小，说数据越干净，杂质越少<br>反之，如果得到的熵越大，说数据越混乱，不同类的数据越多<br>如下面判断是否是猫的问题<br>p1 代表是每组数据中猫的比例，都是猫或狗的话熵 是0，5:5 的时候熵 最大值为1，数据最混乱<br><img src="/image/LLM/139.png" alt><br>具体熵 的计算公式如下<br><img src="/image/LLM/140.png" alt></p><h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><p>在了解熵的含义后，用下面的计算过程选择节点的判断特征<br>根节点的熵减去分类后两个节点熵的加权平均值，值越大说明分类后数据越纯了<br><img src="/image/LLM/141.png" alt><br>这个计算方式得到的值就叫信息增益<br>即特征信息增益越大，在分类过程中，能够把数据分的越纯<br><img src="/image/LLM/142.png" alt></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>决策树学习过程<br><img src="/image/LLM/143.png" alt><br>对于每个节点，都要像对待根节点一样<br>根据拿到的数据先找到最大信息增益的特征然后进行分类<br>整个过程就是一个递归的过程，直到满足停止分类的规则为止<br><img src="/image/LLM/144.png" alt></p><h1 id="多特征值处理办法"><a href="#多特征值处理办法" class="headerlink" title="多特征值处理办法"></a>多特征值处理办法</h1><h2 id="one-hot"><a href="#one-hot" class="headerlink" title="one-hot"></a>one-hot</h2><p>If a categorical feature can take on 𝑘 values, create 𝑘 binary features (0 or 1 valued).<br>如果一个特征有大于2个以上的N可枚举值，那么将当前特征拆分成N个新的代表相应枚举值的特征即可<br><img src="/image/LLM/145.png" alt></p><h2 id="连续值"><a href="#连续值" class="headerlink" title="连续值"></a>连续值</h2><p>如果一个特质的值是连续值，不可枚举，那么需要设定一个阈值，大于该阈值一类，小于则是另一类，从而实现对该特征的二分类<br>阈值的选取还是通过计算信息增益，选取能够使信息增益值最大的阈值参与分类<br>一般情况下先对所有数据按这个特征值排序，然后选取排序列表中两个数据间的中点做阈值进行信息增益计算，<br>多轮计算后再从中选取信息增益最大的阈值<br><img src="/image/LLM/146.png" alt></p><h1 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h1><p>上面是使用决策树进行分类计算<br>接下来使用方差对连续数据进行推测，就是回归树<br>如下图，根据前三个特征，推测weight 的值，weight 是个连续的值，不能枚举的<br><img src="/image/LLM/147.png" alt></p><p><img src="/image/LLM/148.png" alt></p><p><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Advanced%20Learning%20Algorithms/week4/7.Practice%20lab%20decision%20trees/C2_W4_Decision_Tree_with_Markdown.ipynb#scrollTo=5MIhOlYfSm26" target="_blank" rel="noopener">决策树练习</a></p><h1 id="多个决策树"><a href="#多个决策树" class="headerlink" title="多个决策树"></a>多个决策树</h1><p>单个决策树对训练数据非常敏感，只要更改一个训练数据，就有可能更改信息增益排序，<br>从而影响节点特征选择，进而导致整棵树发生变化，使得算法失去健壮性<br>解决办法就是构建多个树，让他们投票最终的预测结果，使整体的算法对任何单个树可能在做什么不那么敏感<br><img src="/image/LLM/149.png" alt></p><h2 id="放回抽样"><a href="#放回抽样" class="headerlink" title="放回抽样"></a>放回抽样</h2><p>一共有m个训练数据，每次从m个数据中随机抽取1个数据，直到抽取到m个数据，抽取到的数据可能是重复的<br><img src="/image/LLM/150.png" alt></p><h2 id="随机森林算法"><a href="#随机森林算法" class="headerlink" title="随机森林算法"></a>随机森林算法</h2><p>使用放回抽样的数据选取方法，每次拿到m个训练数据，用这个m个训练数据训练决策树，重复 B(小于100)次,<br>得到B棵决策树，从而形成决策树森林对预测结果进行投票，这种算法就是随机森林算法<br><img src="/image/LLM/151.png" alt><br>B 如果大于100 一个是训练效果会下降，推测准确性降低，另外一个就是会增加计算成本，使算法变得复杂，得不偿失</p><h3 id="随机特征选取"><a href="#随机特征选取" class="headerlink" title="随机特征选取"></a>随机特征选取</h3><p>对于具备N个特征的数据，通常选择N的K个特征子集进行训练，如果N特别大，K一般等于N的平方根<br><img src="/image/LLM/152.png" alt></p><h2 id="XGBoost-随机森林增强算法"><a href="#XGBoost-随机森林增强算法" class="headerlink" title="XGBoost 随机森林增强算法"></a>XGBoost 随机森林增强算法</h2><p>除了第一次等概率的从m个训练数据中抽样new dataSet 外，后续的每一轮抽样，都将前一轮推测失败的训练数据的权重加大，<br>使被抽取到的概率变高，尽可能的将推测失败的数据参与到后续的训练中，从而推动算法更快的学习，并学习的更好，提高算法的准确性<br><img src="/image/LLM/153.png" alt></p><p>这种算法又称为XGBoost 算法，是随机森林算法的改进版，优点如下<br><img src="/image/LLM/154.png" alt><br><img src="/image/LLM/155.png" alt></p><h1 id="决策树-VS-神经网络"><a href="#决策树-VS-神经网络" class="headerlink" title="决策树 VS 神经网络"></a>决策树 VS 神经网络</h1><p><img src="/image/LLM/156.png" alt></p><h2 id="决策树-amp-决策森林"><a href="#决策树-amp-决策森林" class="headerlink" title="决策树&amp; 决策森林"></a>决策树&amp; 决策森林</h2><p>适合结构化数据(可以用表格表示的数据)<br>不适合非结构化数据（音视频，图像）<br>小的决策树可以被人类解释推测过程<br>训练速度快，缩短算法迭代循环周期，更快的提高算法性能</p><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>对于所有数据类型都很友好，包括结构化和非结构化<br>训练速度比决策树要慢<br>但可以轻松实现迁移学习，但是决策树每次训练只能特定的特征，得到特定的决策树<br>方便构建多模型系统，神经网络间串联方便</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;决策树模型是通过计算特征纯度后，选取最大纯度值的特征作为决策节点，&lt;br&gt;将数据根据是否符合当前特征节点一份为二，再根据特征纯度，继续划分，&lt;br&gt;最后根据停止划分规则进行数据分类或推测的模型&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/image/LLM/136.png&quot; alt
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>机器学习开发过程</title>
    <link href="http://yoohannah.github.io/post/machineLearning/MachineLearningDevelopmentProcess.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/MachineLearningDevelopmentProcess.html</id>
    <published>2024-09-29T08:39:37.000Z</published>
    <updated>2024-11-27T09:37:11.849Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/image/LLM/123.png" alt></p><p>整个开发过程是一个选择框架，训练模型，诊断模型循环的过程</p><h1 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h1><p>除了从高偏差高误差角度对模型进行分析外，还可以对mcv 产生错误分类的角度对模型进行分析<br><img src="/image/LLM/125.png" alt></p><p>可以从交叉验证集测试产生的错误中进行分析<br>通过将错误进行归类统计，找出对模型影响比例较大的错误和比例较小的错误<br>从而调整模型训练的方向，已解决上面遇到的问题<br><img src="/image/LLM/124.png" alt></p><p>如果交叉验证集产生错误的数据比较庞大，可以选择进行随机抽取一定小批量的数据进行错误分类，以节省人力</p><h1 id="添加数据"><a href="#添加数据" class="headerlink" title="添加数据"></a>添加数据</h1><p>通过引入更多数据完善模型的判断，更关注通过注入的数据引发的对模型的训练结果的影响</p><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>Augmentation: modifying an existing training example to create a new training example.<br>在原有数据基础上，通过添加特定种类的噪声，形成新的测试数据，从而完善特定种类的错误判断<br>对于图片和音频数据都适用<br><img src="/image/LLM/126.png" alt><br>但是对添加随机或者无意义噪声产生的数据进行训练，对于模型训练不会有多大帮助</p><h2 id="数据合成"><a href="#数据合成" class="headerlink" title="数据合成"></a>数据合成</h2><p>Synthesis: using artificial data inputs to create a new training example.<br>直接由计算机合成训练过程中使用的数据，通常用于计算机视觉训练的场景<br><img src="/image/LLM/127.png" alt></p><h1 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h1><p>在已有大模型训练结果基础上，通过修改输出层结果使之符合自己使用场景的训练方法<br>好处是，在数据有限的情况下，可以直接使用输出层之前的参数开始训练，减少自己从头开始训练的工作</p><p>例如下面这个使用1000+分类的训练识别数字0-9的模型，只是在输出层将1000+ 输出改成10种输出，在此基础上开始训练<br><img src="/image/LLM/128.png" alt><br>一般训练步骤为下载相同输入(文本的下载文本的，音视频的下载音视频的)的预训练模型，然后用自己的数据进行训练(fine tuning)<br><img src="/image/LLM/129.png" alt></p><h1 id="完整开发流程"><a href="#完整开发流程" class="headerlink" title="完整开发流程"></a>完整开发流程</h1><p><img src="/image/LLM/130.png" alt></p><h2 id="部署阶段"><a href="#部署阶段" class="headerlink" title="部署阶段"></a>部署阶段</h2><p>通常应用层跟模型通过Api 进行通信，用户输入x， 模型返回预测值y^<br>软件工程师需要注意</p><ol><li>尽可能的保障低成本的计算出具有可靠性和有效性的预测结果</li><li>可以进行大规模用户扩展使用</li><li>在用户隐私允许同意的情况下进行日志记录输入和输出</li><li>对模型进行系统监控，比如根据上面日志的记录，计算出因为当前数据变化导致计算结果不准时，判断是否让模型进行进一步优化</li><li>保障模型更新，在上一步进行模型优化后要保证能够将老的模型替换成新模型</li></ol><p><img src="/image/LLM/131.png" alt></p><h1 id="避免道德偏见伦理问题"><a href="#避免道德偏见伦理问题" class="headerlink" title="避免道德偏见伦理问题"></a>避免道德偏见伦理问题</h1><ol><li>建议多元化(多背景，多种族)团队，上线前进行头脑风暴，探索可能对弱势群体造成伤害的可能</li><li>参考行业标准</li><li>上线前通过技术诊断产生的伤害可能性，从而决策是否可以上线</li><li>制定延缓计划，上线后观测可能产生的伤害，及时进行回滚处理<br><img src="/image/LLM/132.png" alt></li></ol><h1 id="二分类错误度量"><a href="#二分类错误度量" class="headerlink" title="二分类错误度量"></a>二分类错误度量</h1><p>在对倾斜数据集(y=1 和y = 0 所占比例不是5:5)进行训练时，<br>判断模型预测结果好坏通常交叉验证集的数据计算精确率和召回率两个指标衡量<br><img src="/image/LLM/133.png" alt><br>如果二者都趋近0或1时，说明当前的模型不是一个有用的模型，一直在打印0或1<br>只有二者值都很大时，才说明算法是有用的</p><p>精确率表示实际上y = 1的可能性<br>召回率表示模型计算出y = 1 的可能性</p><h2 id="对于精确率和召回率的衡量"><a href="#对于精确率和召回率的衡量" class="headerlink" title="对于精确率和召回率的衡量"></a>对于精确率和召回率的衡量</h2><p>一种是通过设置阈值大小去权衡二者，从而进行取舍<br>提高阈值，会增加精度，降低召回率<br>降低阈值，会降低精度，提高召回率<br><img src="/image/LLM/134.png" alt><br>另外一种是使用F1 score分数(调和平均数)，自动计算出最佳的精度和召回率，从而选择对应的算法<br><img src="/image/LLM/135.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/image/LLM/123.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;整个开发过程是一个选择框架，训练模型，诊断模型循环的过程&lt;/p&gt;
&lt;h1 id=&quot;错误分析&quot;&gt;&lt;a href=&quot;#错误分析&quot; class=&quot;headerlink&quot; title=&quot;错误分析&quot;&gt;
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>高偏差和高方差</title>
    <link href="http://yoohannah.github.io/post/machineLearning/biasVariance.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/biasVariance.html</id>
    <published>2024-09-27T09:39:37.000Z</published>
    <updated>2024-11-27T09:37:11.852Z</updated>
    
    <content type="html"><![CDATA[<p>通过判断高方差和高偏差的大小可以判断模型的性能问题<br>一般有以下两个性能问题<br>高偏差意味着模型欠拟合<br>高方差意味着模型过拟合</p><p>高偏差的情况下，<br>Jtrain 值会比较大，且Jtrain和Jcv 值相近<br>也就是说Jtrain 较高对应的训练数据的拟合度本身就不够</p><p>高方差的情况下，<br>Jcv 会远大于Jtrain, Jtrain 值可能比较小<br>就是说模型对训练数据很拟合，但是对交叉验证数据不够拟合</p><p>也有高方差和高偏差两个问题同时存在的情况<br>Jtrain 值会比较大，且Jcv 远大于Jtrain,<br>这种情况意味着模型可能对一些数据过拟合，对一些数据又存在欠拟合</p><p><img src="/image/LLM/109.png" alt></p><h1 id="正则化参数𝜆-对模型的影响"><a href="#正则化参数𝜆-对模型的影响" class="headerlink" title="正则化参数𝜆 对模型的影响"></a>正则化参数𝜆 对模型的影响</h1><p>如果𝜆偏大会导致Jtrain 偏大，出现欠拟合<br>(想象𝜆现在是一个非常大的数值，为使Jtrain 最小，就会让w值逐渐趋近0, 最终模型无限接近b)<br>如果𝜆偏小会导致Jtrain 偏小，但是Jcv 偏大，出现过拟合<br>(想象𝜆现在无限趋近于0，或者直接等于0， 那么要使Jtrain 最小，w取值就得变大，多项式就会被保留，最终模型出现过拟合)<br>如果𝜆取值适中就可以实现Jtrain和Jcv 值都偏低，模型适当拟合的效果<br><img src="/image/LLM/110.png" alt></p><h2 id="𝜆-如何取值"><a href="#𝜆-如何取值" class="headerlink" title="𝜆 如何取值"></a>𝜆 如何取值</h2><p>通过选取不同 𝜆 带入计算最小损失函数，用得到的(w,b)值计算Jcv, 选取多组Jcv 中 最小值的(w,b)进行Jtest 计算，<br><img src="/image/LLM/111.png" alt></p><h2 id="𝜆-趋势图"><a href="#𝜆-趋势图" class="headerlink" title="𝜆 趋势图"></a>𝜆 趋势图</h2><p>𝜆 对于误差的影响趋势和多项式对误差的影响趋势呈镜像关系<br>𝜆 值从小到大，Jtrain 从小到大，模型从过拟合到欠拟合<br>多项式平方数从小到大，Jtrain 从大到小， 模型从欠拟合到过拟合<br><img src="/image/LLM/112.png" alt></p><h1 id="建立性能基准线来判断模型性能"><a href="#建立性能基准线来判断模型性能" class="headerlink" title="建立性能基准线来判断模型性能"></a>建立性能基准线来判断模型性能</h1><p>计算基准线与Jtrain 的差A， A 如果偏大说明模型存在高偏差欠拟合问题<br>计算Jtrain 与 Jcv 的差B，B 如果偏大说明存在高方差过拟合问题<br>如果A 大于B 说明存在高偏差，欠拟合<br>如果A 小于B 说明存在高方差，过拟合<br>如果A 和 B 数值接近，说明 高偏差和高方差同时存在<br><img src="/image/LLM/115.png" alt><br>基准线可以来自<br>人类的测试水平<br>竞争算法的性能水平<br>基于过程经验判断的水平<br><img src="/image/LLM/114.png" alt><br>以 语音识别为例<br><img src="/image/LLM/113.png" alt></p><h1 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h1><p>Jtrain 和Jcv 随 训练集大小m变化的趋势曲线被称为学习曲线</p><p>一般情况下，<br>Jtrain 会随m 变大逐渐变大，因为为了拟合更多数据，数据比一定会散落在曲线上，误差累加起来数值会变大<br>Jcv 会随m 变大逐渐变小，因为更多的数据可以展示更多的情况，是模型拟合度更高，对于Jcv 计算就是越小<br><img src="/image/LLM/116.png" alt></p><p>但是对于存在高偏差的模型，增加样本数量并不一定能对模型拟合产生多大帮助，<br>因为高偏差模型具备欠拟合特点，随样本数增加损失函数也会增加，且相对基本线误差依然存在<br><img src="/image/LLM/117.png" alt></p><p>对于存在高方差的模型，增加样本数量可以起到一定帮助<br>因为高方差模型具体过拟合特点，会将增加的样本继续拟合到自己的训练模型中，相当容纳近了更多的数据情况<br>可以更好的拟合实际的情况<br><img src="/image/LLM/118.png" alt></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>高偏差和高方差的一些解决方案<br><img src="/image/LLM/119.png" alt></p><h1 id="神经网络中的应用"><a href="#神经网络中的应用" class="headerlink" title="神经网络中的应用"></a>神经网络中的应用</h1><p>神经网络是低偏差的模型，<br>在训练过程中如果Jtrain 过大可以使用更大的神经网络，缺点就是运算速度会变低且会增加研发成本<br>在Jtrain 基本与基准线相差不大时计算Jvc，如果Jvc 过大可以增加数据样本重新回到模型计算<br>经过上面不断重复的过程，最终得到合适的模型参数<br><img src="/image/LLM/120.png" alt><br>只要数据规则化做的合适，大型神经网络总是会比小型神经网络表现好一些<br><img src="/image/LLM/121.png" alt><br>在tensorFlow 中，可以在构建layer 时传入规则化参数<br><img src="/image/LLM/122.png" alt></p><h1 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h1><p>练习多项式，正则化参数𝜆，训练数据个数m, 神经网络层数<br><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Advanced%20Learning%20Algorithms/week3/8.Practice%20Lab%20Advice%20for%20applying%20machine%20learning/C2_W3_Assignment.ipynb#scrollTo=3tnHtCF35uzg" target="_blank" rel="noopener">链接</a></p><p>The simple model is a bit better in the training set than the regularized model but it worse in the cross validation set.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;通过判断高方差和高偏差的大小可以判断模型的性能问题&lt;br&gt;一般有以下两个性能问题&lt;br&gt;高偏差意味着模型欠拟合&lt;br&gt;高方差意味着模型过拟合&lt;/p&gt;
&lt;p&gt;高偏差的情况下，&lt;br&gt;Jtrain 值会比较大，且Jtrain和Jcv 值相近&lt;br&gt;也就是说Jtrain 较高对应
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>一些其他的概念</title>
    <link href="http://yoohannah.github.io/post/machineLearning/advanceOpt.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/advanceOpt.html</id>
    <published>2024-09-25T08:27:37.000Z</published>
    <updated>2024-11-27T09:37:11.851Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Adam-Algorithm"><a href="#Adam-Algorithm" class="headerlink" title="Adam Algorithm"></a>Adam Algorithm</h1><p>一种加快模型学习的优化算法<br> 可以自动调节学习率的大小，使模型更快的朝梯度下降的方向学习<br> <img src="/image/LLM/96.png" alt><br> <img src="/image/LLM/97.png" alt><br> <img src="/image/LLM/98.png" alt></p><h1 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h1><p> 之前讨论的神经网络中的中间层，都依赖上一层所有的输出进行计算<br> Each neuron output is a function of<br> all the activation outputs of the previous layer.<br> 有一种计算方案是只选取上一层的部分数据计算本层的输出<br> 这种layer 被称为卷积层（Convolutional Layer）<br> 优点有两个<br> 一个是可以加快计算，<br> 另外一个是可以减少需要的训练数据</p><p>  <img src="/image/LLM/99.png" alt></p><h1 id="降低预测结果错误率"><a href="#降低预测结果错误率" class="headerlink" title="降低预测结果错误率"></a>降低预测结果错误率</h1><p>拿到训练模型后，如果遇到一个不可接受的错误输出，可以通过以下方式进行重新调整<br><img src="/image/LLM/100.png" alt></p><p>更常见的方式是用诊断的方式评估模型好坏<br>在训练前将数据分成两组，<br>一组用于模型训练，称为训练组<br>另一组用于测试训练得到的模型，称为测试组</p><p>比如对于过拟合的情况<br>将数据分成两组<br><img src="/image/LLM/101.png" alt><br>分别计算训练组和测试组的损失函数<br><img src="/image/LLM/102.png" alt><br>对于训练组数据的损失函数肯定会更小<br>要关注的是测试数据的损失函数，值越小，说明越近真实的值，说明模型越好<br>上面是线性回归模型，下面是对于分类问题的损失函数计算<br><img src="/image/LLM/103.png" alt></p><p><img src="/image/LLM/104.png" alt></p><p>如果需要在多个模型间进行选择，可以在一开始的时候将数据分成三组<br>训练组，交叉验证组，测试组</p><p>同样计算基于交叉验证组数据的损失函数，值越小说明越符合实际数据<br>主要作用是用于选择模型，比如挑出最合适的多项式</p><p>然后再使用测试组数据进行泛化错误的测试</p><p><img src="/image/LLM/105.png" alt><br><img src="/image/LLM/106.png" alt><br><img src="/image/LLM/107.png" alt><br><img src="/image/LLM/108.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Adam-Algorithm&quot;&gt;&lt;a href=&quot;#Adam-Algorithm&quot; class=&quot;headerlink&quot; title=&quot;Adam Algorithm&quot;&gt;&lt;/a&gt;Adam Algorithm&lt;/h1&gt;&lt;p&gt;一种加快模型学习的优化算法&lt;br&gt; 可以自动
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>多分类问题</title>
    <link href="http://yoohannah.github.io/post/machineLearning/softMax.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/softMax.html</id>
    <published>2024-09-25T08:27:37.000Z</published>
    <updated>2024-11-27T09:37:11.860Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Softmax-regression"><a href="#Softmax-regression" class="headerlink" title="Softmax regression"></a>Softmax regression</h1><p>之前的二分类问题用logic regression 可以解决，<br>但是对于多分类问题，可以在此基础上，遵循所有可能性加和为1的原则<br>进行扩展</p><p>假如现在需要判断4种可能性的概率<br>那我们需要四条分界线（如下图在z1-z4）<br>然后通过通过下面这个公式<br><img src="/image/LLM/87.png" alt><br>计算得到a1 - a4<br>就可以得到4种可能性的概率</p><p>这种算法就是 Softmax regression<br><img src="/image/LLM/86.png" alt></p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>参照逻辑回归函数的损失函数<br>假如y = 1, 那么损失函数就是<br><img src="/image/LLM/88.png" alt><br>y = 0 的话损失函数就是<br><img src="/image/LLM/89.png" alt></p><p>归纳一下就是，当y = an时<br>损失函数就是Loss = -log(an)<br>因为 y 只能可能是a1-an N 种可能性中的一种<br>下面的Loss趋势图说明，当an 值越接近1 的时候 损失函数越小<br>也就是说a1 - an 这些概率值越接近1 损失函数越小<br>相当于概率值对应的可能性越可能接近真实y值，越准<br><img src="/image/LLM/90.png" alt></p><h2 id="在神经网络中使用"><a href="#在神经网络中使用" class="headerlink" title="在神经网络中使用"></a>在神经网络中使用</h2><p>之前的二分类问题中，在神经网络的最后一层使用sigmoid 函数作为输出函数（或者激活函数）可以识别图片中的 0 和 1<br>现在如果要识别图片中的数字是0-9 10种分类中的哪一种，<br>要做的就是将输出层激活函数换成softmax 函数，并且是10个节点就可以实现<br>每个节点代表一种可能，值最大的就是可能性最大的值</p><p><img src="/image/LLM/91.png" alt></p><h2 id="tensorFlow-中实现"><a href="#tensorFlow-中实现" class="headerlink" title="tensorFlow 中实现"></a>tensorFlow 中实现</h2><p>方案1<br><img src="/image/LLM/92.png" alt><br>不推荐，用方案2优化</p><p>方案2<br><img src="/image/LLM/93.png" alt></p><p>原因是在tensorFlow 中使用中间步骤计算数值和直接将式子带入计算最终值的处理过程不同，tensorflow 会对后者重新排列表达式中的术语<br>并想出一种更准确的计算方式去计算，方案二在方案一基础上做的修改就是在将式子带入计算，而不是先计算中间值，再带入</p><h1 id="区别多标签多分类问题"><a href="#区别多标签多分类问题" class="headerlink" title="区别多标签多分类问题"></a>区别多标签多分类问题</h1><p>上面讨论的是多分类问题，一个问题多个可能性<br> 多标签多分类问题是指同时推测多个问题的多个可能性<br><img src="/image/LLM/94.png" alt><br> 计算方式可以是分别看成单个神经网络计算，一个神经网络处理一个问题的多种可能<br> 也可以同时计算，输出多个问题对应的多个可能<br> <img src="/image/LLM/95.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Softmax-regression&quot;&gt;&lt;a href=&quot;#Softmax-regression&quot; class=&quot;headerlink&quot; title=&quot;Softmax regression&quot;&gt;&lt;/a&gt;Softmax regression&lt;/h1&gt;&lt;p&gt;之前的二分类
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>神经网络</title>
    <link href="http://yoohannah.github.io/post/machineLearning/neuralNetworks.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/neuralNetworks.html</id>
    <published>2024-09-20T09:27:37.000Z</published>
    <updated>2024-11-27T09:37:11.858Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是神经网络"><a href="#什么是神经网络" class="headerlink" title="什么是神经网络"></a>什么是神经网络</h1><p>类似于大脑中的神经元传递信息的过程，将多个输入通过多层模型处理后得到结果输出的架构，就是神经网络</p><p><img src="/image/LLM/67.png" alt><br><img src="/image/LLM/68.png" alt><br><img src="/image/LLM/69.png" alt></p><p>复杂神经网络的表示<br><img src="/image/LLM/70.png" alt><br>从预测手写数据0和1 的过程，理解神经网络向前传播的计算原理<br><img src="/image/LLM/71.png" alt></p><p>The parameters have dimensions that are sized for a neural network with  25  units in layer 1,  15  units in layer 2 and  1  output unit in layer 3.<br>the dimensions of these parameters are determined as follows:<br>If network has  𝑠𝑖𝑛  units in a layer and  𝑠𝑜𝑢𝑡  units in the next layer, then<br>𝑊  will be of dimension  𝑠𝑖𝑛×𝑠𝑜𝑢𝑡 .<br>𝑏  will a vector with  𝑠𝑜𝑢𝑡  elements<br>Therefore, the shapes of W, and b, are<br>layer1: The shape of W1 is (400, 25) and the shape of b1 is (25,)<br>layer2: The shape of W2 is (25, 15) and the shape of b2 is: (15,)<br>layer3: The shape of W3 is (15, 1) and the shape of b3 is: (1,)<br>Note: The bias vector b could be represented as a 1-D (n,) or 2-D (n,1) array. Tensorflow utilizes a 1-D representation and this lab will maintain that convention.</p><p>向前传播：从左到右计算，根据输入计算出输出，输出即预测结果，<br><img src="/image/LLM/72.png" alt></p><p>使用tensorflow 实现向前传播的神经网络<br><img src="/image/LLM/73.png" alt></p><p>具体实现<br><img src="/image/LLM/77.png" alt><br><img src="/image/LLM/78.png" alt><br><img src="/image/LLM/76.png" alt></p><p>Tensorflow models are built layer by layer. A layer’s input dimensions ( 𝑠𝑖𝑛  above) are calculated for you. You specify a layer’s output dimensions and this determines the next layer’s input dimension. The input dimension of the first layer is derived from the size of the input data specified in the model.fit statment below.</p><p>Note: It is also possible to add an input layer that specifies the input dimension of the first layer. For example:<br>tf.keras.Input(shape=(400,)), #specify input shape<br>We will include that here to illuminate some model sizing.</p><p>调用numpy()方法可以实现张量和numpy matrix 之间的转换<br><img src="/image/LLM/74.png" alt><br>使用tensorflow 实现神经网络的另外一种架构形式<br><img src="/image/LLM/75.png" alt></p><p>The model.compile statement defines a loss function and specifies a compile optimization.<br>The model.fit statement runs gradient descent and fits the weights to the data.</p><p><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Advanced%20Learning%20Algorithms/week1/9.Practice%20Lab%20Neural%20networks/C2_W1_Assignment.ipynb#scrollTo=qI3g3oYtRTZp" target="_blank" rel="noopener">图片识别0和1练习</a></p><h1 id="神经网络的训练过程"><a href="#神经网络的训练过程" class="headerlink" title="神经网络的训练过程"></a>神经网络的训练过程</h1><p><img src="/image/LLM/78.png" alt><br><img src="/image/LLM/79.png" alt><br><img src="/image/LLM/80.png" alt><br><img src="/image/LLM/81.png" alt><br><img src="/image/LLM/82.png" alt><br><img src="/image/LLM/83.png" alt></p><h2 id="如何选择激活函数"><a href="#如何选择激活函数" class="headerlink" title="如何选择激活函数"></a>如何选择激活函数</h2><p>常见的三种激活函数<br><img src="/image/LLM/84.png" alt></p><p>选择激活函数的一般规则<br>对于输出层，根据输出值来<br>如果是二分类问题，使用sigmoid<br>如果是输出正负值都有就选则线性激活函数<br>如果输出值非负，那么 就使用ReLu函数<br>对于中间层，一律使用ReLu函数<br>原因有三</p><ol><li>一个是作为激活函数，本身计算过程比sigmoid 函数简单</li><li>relu只有在小于0 的时候斜率为0，sigmoid 函数在趋向正负无穷的时候有两处斜率趋近0 的情况，会导致梯度下降计算过程变慢，所以ReLu函数在梯度下降过程相比之下会更快一些</li><li>如果在隐藏层使用线性激活函数，输出层是sigmoid函数，整个过程等同于线性回归，最终始终会变成二分类的结果</li></ol><p><img src="/image/LLM/85.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;什么是神经网络&quot;&gt;&lt;a href=&quot;#什么是神经网络&quot; class=&quot;headerlink&quot; title=&quot;什么是神经网络&quot;&gt;&lt;/a&gt;什么是神经网络&lt;/h1&gt;&lt;p&gt;类似于大脑中的神经元传递信息的过程，将多个输入通过多层模型处理后得到结果输出的架构，就是神经网络&lt;/
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>解决过拟合问题</title>
    <link href="http://yoohannah.github.io/post/machineLearning/overfitting.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/overfitting.html</id>
    <published>2024-09-17T13:05:37.000Z</published>
    <updated>2024-11-27T09:37:11.858Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是过拟合"><a href="#什么是过拟合" class="headerlink" title="什么是过拟合"></a>什么是过拟合</h1><p>训练得到的预测模型对于每个训练数据都非常吻合，导致对于新的测试数据无法正确评估的现象，就是过拟合<br>下面是线性回归和逻辑回归模型三种训练结果的展示<br><img src="/image/LLM/57.png" alt><br><img src="/image/LLM/58.png" alt></p><h1 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h1><ol><li>收集更多的数据进行训练</li><li>选择和使用有价值的特性值参与运算</li><li>减小部分特征值(对于结果预测关系不大的特征值)的参数值（正则化）</li></ol><h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p>在成本函数或者损失函数中增加正则化参数，避免过拟合<br><img src="/image/LLM/59.png" alt></p><p>在梯度下降计算过程中，会使得每个参数在原来基础上乘以一个比1小的数据再去进行减法运算，从而使得梯度下降过程中实现参数进一步缩小<br><img src="/image/LLM/60.png" alt><br><img src="/image/LLM/61.png" alt></p><p>cost and gradient functions for both linear and logistic regression. Note:</p><p>Cost</p><p>The cost functions differ significantly between linear and logistic regression, but adding regularization to the equations is the same.</p><p>Gradient</p><p>The gradient functions for linear and logistic regression are very similar. They differ only in the implementation of $f_{wb}$.</p><h2 id="线性回归正则化"><a href="#线性回归正则化" class="headerlink" title="线性回归正则化"></a>线性回归正则化</h2><p><img src="/image/LLM/62.png" alt><br><img src="/image/LLM/63.png" alt><br><img src="/image/LLM/64.png" alt></p><h2 id="逻辑回归正则化"><a href="#逻辑回归正则化" class="headerlink" title="逻辑回归正则化"></a>逻辑回归正则化</h2><p><img src="/image/LLM/65.png" alt><br><img src="/image/LLM/66.png" alt></p><h1 id="实践案例"><a href="#实践案例" class="headerlink" title="实践案例"></a><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Supervised%20Machine%20Learning%20Regression%20and%20Classification/week3/9.Week%203%20practice%20lab%20logistic%20regression/C1_W3_Logistic_Regression.ipynb#scrollTo=T8l3AKj8R29G" target="_blank" rel="noopener">实践案例</a></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;什么是过拟合&quot;&gt;&lt;a href=&quot;#什么是过拟合&quot; class=&quot;headerlink&quot; title=&quot;什么是过拟合&quot;&gt;&lt;/a&gt;什么是过拟合&lt;/h1&gt;&lt;p&gt;训练得到的预测模型对于每个训练数据都非常吻合，导致对于新的测试数据无法正确评估的现象，就是过拟合&lt;br&gt;下面
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归模型</title>
    <link href="http://yoohannah.github.io/post/machineLearning/logicRegression.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/logicRegression.html</id>
    <published>2024-09-17T11:31:37.000Z</published>
    <updated>2024-11-27T09:37:11.856Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景-amp-amp-解决问题"><a href="#背景-amp-amp-解决问题" class="headerlink" title="背景&amp;&amp;解决问题"></a>背景&amp;&amp;解决问题</h1><p>逻辑回归模型时一种解决二分类问题的算法</p><p>如果用线性回归去解决分类问题，会导致过拟合出现，每增加一个测试数据，都可能导致模型发生变化</p><p><img src="/image/LLM/40.png" alt></p><p>通过使用sigmoid function函数，设置阈值，可以将线性回归产生的结果归类到两个结果上去</p><p><img src="/image/LLM/41.png" alt></p><p><img src="/image/LLM/42.png" alt></p><p>虽然目标是二分类，即结果只能是0 或者1<br>但是f(w,b) = g(w·x+b) 计算的结果值A只能无限接近这两个值<br>这里可以将A理解成结果是1 的可能性</p><p><img src="/image/LLM/43.png" alt></p><h2 id="决策边界"><a href="#决策边界" class="headerlink" title="决策边界"></a>决策边界</h2><p>在逻辑回归模型f(w,b) = g(w·x+b)  中<br>z = w·x+b 又称为 决策边界，将不同结果的数据在坐标系中进行隔离<br>如果特征在z 中没有多项式运算，那么，得到的边界必定是直线的，但是如果有多项式，拿得到的边界线就是非线性的<br><img src="/image/LLM/44.png" alt><br><img src="/image/LLM/45.png" alt><br><img src="/image/LLM/46.png" alt><br><img src="/image/LLM/47.png" alt></p><h2 id="成本函数"><a href="#成本函数" class="headerlink" title="成本函数"></a>成本函数</h2><p>线性回归的平方误差算法的成本函数在应用到逻辑回归时，会产生多个局部最小值，再用梯度下降的算法去找参数时，无法找到最小值</p><p><img src="/image/LLM/48.png" alt></p><p>逻辑回归引入逻辑损失函数，根据单个数据集随参数变化的趋势，判断整体的变化趋势<br>操作就是将原本平方误差除以2的操作移到求和之前，单独计算每个特征值的部分就是损失函数</p><p>Logistic Regression uses a loss function more suited to the task of categorization where the target is 0 or 1 rather than any number.</p><p>these definitions are used:</p><p>Loss is a measure of the difference of a single example to its target value while the</p><p>Cost is a measure of the losses over the training set</p><p>下面是推导过程和最终的式子</p><p><img src="/image/LLM/49.png" alt><br><img src="/image/LLM/50.png" alt><br><img src="/image/LLM/51.png" alt><br><img src="/image/LLM/52.png" alt><br><img src="/image/LLM/53.png" alt></p><h2 id="梯度下降找到w-amp-b"><a href="#梯度下降找到w-amp-b" class="headerlink" title="梯度下降找到w&amp;b"></a>梯度下降找到w&amp;b</h2><p><img src="/image/LLM/54.png" alt><br><img src="/image/LLM/55.png" alt><br><img src="/image/LLM/56.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;背景-amp-amp-解决问题&quot;&gt;&lt;a href=&quot;#背景-amp-amp-解决问题&quot; class=&quot;headerlink&quot; title=&quot;背景&amp;amp;&amp;amp;解决问题&quot;&gt;&lt;/a&gt;背景&amp;amp;&amp;amp;解决问题&lt;/h1&gt;&lt;p&gt;逻辑回归模型时一种解决二分类问题
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>线性回归模型</title>
    <link href="http://yoohannah.github.io/post/machineLearning/lineregression.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/lineregression.html</id>
    <published>2024-09-07T11:31:37.000Z</published>
    <updated>2024-11-27T09:37:11.855Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一些专业术语表达"><a href="#一些专业术语表达" class="headerlink" title="一些专业术语表达"></a>一些专业术语表达</h1><p><img src="/image/LLM/1.png" alt><br><img src="/image/LLM/2.png" alt><br>x–&gt; 训练数据入参，特征值，这里仅有一个，这个模型也被叫做 单变量线性回归模型 x(i) 第i个训练数据的x<br>y–&gt; 训练数据入参，标记值， example 的lable ,y(i) 第i个训练数据的y<br>y-hat –&gt; 出参，推测值, 模型（f（x）= wx + b） 的 结果值</p><h1 id="成本函数"><a href="#成本函数" class="headerlink" title="成本函数"></a>成本函数</h1><h2 id="平方误差成本函数"><a href="#平方误差成本函数" class="headerlink" title="平方误差成本函数"></a>平方误差成本函数</h2><p><img src="/image/LLM/3.png" alt><br>在f(x) = wx+ b 的模型中<br>w: 斜率<br>b: 截距，intercepter 直接与Y轴交点距离远点距离</p><p>用J(w,b)表示成本函数，找到能够使J(w,b) 的值最小的w和b，就可以找到使f(x)最接近所有测试集的模型，最拟合训练数据的模型<br>先讨论在b = 0 的情况下，j（w） 随w 变化的趋势<br><img src="/image/LLM/4.png" alt><br>找到使j(w) 最小的w,即U形线最凹的地方<br><img src="/image/LLM/5.png" alt><br>现在把b的变化趋势也加入讨论，j(w,b) 随w，b 变化的趋势，将变成3d 的碗状<br><img src="/image/LLM/6.png" alt><br>最凹的地方就是J(w,b)值最小的地方<br><img src="/image/LLM/7.png" alt><br>利用等高线的表达方式，换一种视角找J(w,b)的最小值，就是将3D 图进行水平切割，得到关于w,b 的二维椭圆视图<br>不同(w,b) 组合可能会落在在同一条线上的，相同线上的J(w,b)值一样大<br>所以能够使J(w,b)值最小的(w,b)值，就是同心圆里面最里面那个圆上的多对(w,b), 当圆极限到一个点时，就只有一对(w,b)使J(w,b)最小<br><img src="/image/LLM/8.png" alt><br><img src="/image/LLM/9.png" alt></p><h1 id="GradientDescentAlgorithm-梯度下降算法"><a href="#GradientDescentAlgorithm-梯度下降算法" class="headerlink" title="GradientDescentAlgorithm 梯度下降算法"></a>GradientDescentAlgorithm 梯度下降算法</h1><p>是一种寻找使成本函数达到最小值参数的通用算法，现在不再局限与于f(x) = wx+b 单变量线性模型<br>对于多变量模型，也就意味着多个w, 这样J(w,b) 就会变成J(w0,…wi,b), J(w0, …wi) 的趋势不再是U形<br><img src="/image/LLM/10.png" alt><br>梯度下降指的是，从一个点出发，环顾四周，找到能够下降的谷底的最快的方向，即梯度最陡的方向，下降一步，每走一步都按最陡方案下降，从而实现最快到达谷底的目的<br>达到谷底即意味着找到J(w0,…wi,b)最小值<br>但是梯度下降有一个特性，就是，虽然从同一点出发，如果第一步选择反向不同，或者走的方式不同，肯定会到达不同谷底<br>不同谷底意味着不同的J(w0,…wi,b)最小值，这些最小值，都叫做局部最小值<br><img src="/image/LLM/11.png" alt></p><h3 id="算法实现与理解"><a href="#算法实现与理解" class="headerlink" title="算法实现与理解"></a>算法实现与理解</h3><p>J(w,b)关于w 导数 表征 U形趋势线上随w 变化的梯度值，也就是斜率<br>前面的系数α表征 下坡的步伐大小 是一个0-1 的正小数值，称为学习率<br>w,b 同时变化，同时更新<br><img src="/image/LLM/12.png" alt><br>当梯度大于0时，temp_w 逐渐变小，J(w,b) 的值也逐渐变小<br>当梯度小于0 时，temp_w 逐渐变大（负斜率，绝对值在变小）， J(w,b)的值逐渐变小<br>说明J(w,b) 的值随梯度的变化符合随w的变化趋势<br>当斜率绝对值逐渐变小时，就是都朝J(w,b) 最小值聚拢<br><img src="/image/LLM/13.png" alt><br><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Supervised%20Machine%20Learning%20Regression%20and%20Classification/week1/work/C1_W1_Lab05_Gradient_Descent_Soln.ipynb" target="_blank" rel="noopener">实验</a></p><h4 id="关于学习率"><a href="#关于学习率" class="headerlink" title="关于学习率"></a>关于学习率</h4><p>太小会增加计算步骤，从而使梯度算法变慢<br>太大可能导致过冲，永远无法到达最小值;甚至无法实现聚拢趋势，导致发散<br><img src="/image/LLM/14.png" alt></p><h3 id="局部最小值"><a href="#局部最小值" class="headerlink" title="局部最小值"></a>局部最小值</h3><p>如果当前参数已经使得成本函数到达一个局部最小值，那么J(w,b) 关于w 导数值将会是0，那么temp_w 会始终停留在一个固定的值，不再变化<br>梯度下降算法将不会再进行下一步的计算，保持当前参数在当前的这个一个局部最小值的状态</p><p>随这个梯度下降，我们可以知道我们正在朝成本函数最小值靠近，在学习率固定情况下，更新步骤也在下降(斜率本身朝0在逐渐变小)，说明没有学习率的变化，也能到达局部最小值<br>但如果同时将学习率调小，降低下降的步伐，可以更小幅度的一点点接近最小值，最终找到成本函数最小值<br><img src="/image/LLM/15.png" alt></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>线性回归模型，成本函数，和梯度下降算法<br><img src="/image/LLM/16.png" alt><br><img src="/image/LLM/17.png" alt><br>上述梯度下降算法具体来说是批量梯度下降，因为每一步都用到了所有训练数据<br><img src="/image/LLM/18.png" alt></p><h1 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h1><p>以上讨论的是只有一个特征值x 作为输入的情况，下面要讨论的是同时有n个特征值做输入的模型，被称为多元线性回归模型</p><p>一些符号的表示方法<br><img src="/image/LLM/19.png" alt></p><h2 id="模型表达式"><a href="#模型表达式" class="headerlink" title="模型表达式"></a>模型表达式</h2><p><img src="/image/LLM/20.png" alt><br><img src="/image/LLM/21.png" alt></p><h2 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h2><p>好处</p><ol><li>代码实现简洁</li><li>运算速度快</li></ol><p><img src="/image/LLM/22.png" alt><br><img src="/image/LLM/23.png" alt><br><img src="/image/LLM/24.png" alt></p><h2 id="对于多元线性回归-的-梯度下降算法"><a href="#对于多元线性回归-的-梯度下降算法" class="headerlink" title="对于多元线性回归 的 梯度下降算法"></a>对于多元线性回归 的 梯度下降算法</h2><p>w 相关的计算转成向量计算，不同权重值，取对应特征值进行计算<br><img src="/image/LLM/25.png" alt><br><img src="/image/LLM/26.png" alt></p><p><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Supervised%20Machine%20Learning%20Regression%20and%20Classification/week2/1.Multiple%20linear%20regression/C1_W2_Lab02_Multiple_Variable_Soln.ipynb" target="_blank" rel="noopener">实验</a></p><h1 id="实践技巧"><a href="#实践技巧" class="headerlink" title="实践技巧"></a>实践技巧</h1><p>如何更快的找到合适的参数去拟合训练集</p><h2 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h2><h3 id="参数大小与特征值大小关系"><a href="#参数大小与特征值大小关系" class="headerlink" title="参数大小与特征值大小关系"></a>参数大小与特征值大小关系</h3><p>如果某一特征值(x1 属于[1000,5000]范围)相对其他特征值(x2,x3,..xn,属于[1,10]范围),数值范围较大，其对应参数w1 则相对其他较小<br>反之，如果特征值较小，则参数较大，这样的规律可以更快的找到适合的参数<br><img src="/image/LLM/27.png" alt><br><img src="/image/LLM/28.png" alt><br>如果特征值的取值范围非常不同时，会导致梯度下降速度变慢<br>但如果将所有特征值想办法归一到相同的范围内，就可以加快梯度下降过程，降低计算步骤<br><img src="/image/LLM/29.png" alt></p><h3 id="缩放计算方式"><a href="#缩放计算方式" class="headerlink" title="缩放计算方式"></a>缩放计算方式</h3><h4 id="除以最大值"><a href="#除以最大值" class="headerlink" title="除以最大值"></a>除以最大值</h4><p>特征值除以各自范围的最大值<br><img src="/image/LLM/30.png" alt></p><h4 id="均值归一化"><a href="#均值归一化" class="headerlink" title="均值归一化"></a>均值归一化</h4><p>特征值 减去平均值，再除以极差值(范围最大值减去范围最小值)<br><img src="/image/LLM/31.png" alt></p><h4 id="Z-SCORE归一化"><a href="#Z-SCORE归一化" class="headerlink" title="Z-SCORE归一化"></a>Z-SCORE归一化</h4><p>特征值 减去 标准差，除以 平均值<br><img src="/image/LLM/32.png" alt></p><h4 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h4><p>并不一定非要落在-1 到1 之间，落在相同的数量级之间就可接受<br><img src="/image/LLM/33.png" alt></p><h2 id="如何找到成本函数最小值"><a href="#如何找到成本函数最小值" class="headerlink" title="如何找到成本函数最小值"></a>如何找到成本函数最小值</h2><h3 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h3><p>绘制成本函数随迭代次数变化的趋势图，称为学习曲线，主要是根据曲线走势判断梯度是否在收敛<br>如果随迭代次数增加，成本函数一直呈下降趋势，说明梯度正在下降，是正常的<br>当下降到一定程度，随迭代次数成本函数不再有明显下降，说明梯度收敛到了极限，也就是找到了成本函数的最低点<br>但如果随次数增加，成本函数出现上升，这是不正常的，则说明学习率选取过大，需要重新选取，或者代码出现错误</p><h3 id="自动收敛测试"><a href="#自动收敛测试" class="headerlink" title="自动收敛测试"></a>自动收敛测试</h3><p>自行定义一个极小的值，当某次迭代后成本函数值小于该值时，就认为梯度下降关闭，成本函数达到最小值，停止迭代，取当前迭代wb做模型参数<br>缺点就是极小值难以估计，且结果不太可靠<br><img src="/image/LLM/34.png" alt></p><h2 id="如何选择合适学习率"><a href="#如何选择合适学习率" class="headerlink" title="如何选择合适学习率"></a>如何选择合适学习率</h2><p>根据学习曲线调整学习率<br>学习率太大会导致学习曲线出现上升趋势<br>太小会导致迭代次数增加<br><img src="/image/LLM/35.png" alt><br>可以先对不同量级的学习率进行测试，观察学习曲线变化快慢<br>然后进行N倍测试，再比较，通过多组测试观察学习曲线变化快慢进行选取<br><img src="/image/LLM/36.png" alt></p><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>通过转换或者合并直接(原始)的特征值，生成新的特征值进行模型训练<br><img src="/image/LLM/37.png" alt></p><h2 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h2><p>如果特征值只有一个的情况下，不希望得到线性回归的直线模型，希望用曲线去拟合训练集<br>可以采用下面两种方法去拟合</p><ol><li>通乘方构建新特征值，但是在进行训练时要进行归一化处理，因为乘方处理后，各个特质值范围的数量级会变得不同</li><li>通过开方进行新特征值构建<br><img src="/image/LLM/38.png" alt></li></ol><h1 id="如何在colab中运行github-上的jupiter文件"><a href="#如何在colab中运行github-上的jupiter文件" class="headerlink" title="如何在colab中运行github 上的jupiter文件"></a>如何在colab中运行github 上的jupiter文件</h1><p>下面这个链接时梯度下降实现的.ipynb 文件</p><p><a href="https://github.com/kaieye/2022-Machine-Learning-Specialization/blob/main/Supervised%20Machine%20Learning%20Regression%20and%20Classification/week1/work/C1_W1_Lab05_Gradient_Descent_Soln.ipynb" target="_blank" rel="noopener">https://github.com/kaieye/2022-Machine-Learning-Specialization/blob/main/Supervised%20Machine%20Learning%20Regression%20and%20Classification/week1/work/C1_W1_Lab05_Gradient_Descent_Soln.ipynb</a></p><p>复制域名之后的path<br>kaieye/2022-Machine-Learning-Specialization/blob/main/<br>Supervised%20Machine%20Learning%20Regression%20and%20Classification/week1/work/C1_W1_Lab05_Gradient_Descent_Soln.ipynb<br>拼接到 <a href="https://colab.research.google.com/github/" target="_blank" rel="noopener">https://colab.research.google.com/github/</a> 后面</p><p>得到访问链接</p><p><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Supervised%20Machine%20Learning%20Regression%20and%20Classification/week1/work/C1_W1_Lab05_Gradient_Descent_Soln.ipynb" target="_blank" rel="noopener">https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Supervised%20Machine%20Learning%20Regression%20and%20Classification/week1/work/C1_W1_Lab05_Gradient_Descent_Soln.ipynb</a></p><p>如果.ipynb有依赖其他py 文件，可以点击上传图标直接上传<br><img src="/image/LLM/39.png" alt></p><p>但是要注意这里上传的文件都是运行时的状态，页面关闭即销毁，<br>如果想要保存自己修改后的.ipynb文件可以通过添加副本到google/drive 来实现</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一些专业术语表达&quot;&gt;&lt;a href=&quot;#一些专业术语表达&quot; class=&quot;headerlink&quot; title=&quot;一些专业术语表达&quot;&gt;&lt;/a&gt;一些专业术语表达&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/image/LLM/1.png&quot; alt&gt;&lt;br&gt;&lt;img src=&quot;
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>机器学习定义</title>
    <link href="http://yoohannah.github.io/post/machineLearning/definition.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/definition.html</id>
    <published>2024-09-02T00:10:37.000Z</published>
    <updated>2024-11-27T09:37:11.854Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h1><p>filed of study that gives computers the ability to learn without being explicity programmed.</p><p>让计算机在没有明确编程的情况下学习的研究领域</p><p>– Arthur Samuel (1959)</p><h1 id="Supervised-Learning-监督学习"><a href="#Supervised-Learning-监督学习" class="headerlink" title="Supervised Learning 监督学习"></a>Supervised Learning 监督学习</h1><p>learns from being given ‘right answers’</p><p>learns from  data labeled with ‘right answers’</p><h2 id="regression-algorithms-回归算法"><a href="#regression-algorithms-回归算法" class="headerlink" title="regression algorithms 回归算法"></a>regression algorithms 回归算法</h2><p>从无限多可能数字中预测数字</p><p>predict a number 预测无限可能中的一种<br>infinitely many possible outputs</p><h2 id="classify-algorithms-分类算法"><a href="#classify-algorithms-分类算法" class="headerlink" title="classify algorithms 分类算法"></a>classify algorithms 分类算法</h2><p>predict categories 预测有限分类中的一类<br>small number of possible outputs</p><h1 id="Unsupervised-Learning-无监督学习"><a href="#Unsupervised-Learning-无监督学习" class="headerlink" title="Unsupervised Learning 无监督学习"></a>Unsupervised Learning 无监督学习</h1><p>find sth interesting in unlabeled data<br>data only comes with input x ,but not output labels y, algorithm has to find structure in the data</p><h2 id="clustering-algorithms-聚类算法"><a href="#clustering-algorithms-聚类算法" class="headerlink" title="clustering algorithms 聚类算法"></a>clustering algorithms 聚类算法</h2><p>place the unlabeled data (automatically group) into different clusters</p><p>eg. google news, grouping customers</p><p>==&gt; group similar data points together</p><h2 id="Anomaly-detection-异常检测"><a href="#Anomaly-detection-异常检测" class="headerlink" title="Anomaly detection 异常检测"></a>Anomaly detection 异常检测</h2><p> find unusal data points (events)</p><p> eg. 金融诈骗中的交易异常</p><h2 id="Dimensionality-reduction-降维算法"><a href="#Dimensionality-reduction-降维算法" class="headerlink" title="Dimensionality reduction  降维算法"></a>Dimensionality reduction  降维算法</h2><p>compressn data using fewer numbers</p><p>压缩大数据集到小数据集，同时丢失尽可能少的信息</p><h2 id="Reinforcement-Learning-强化学习"><a href="#Reinforcement-Learning-强化学习" class="headerlink" title="Reinforcement Learning 强化学习"></a>Reinforcement Learning 强化学习</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;什么是机器学习&quot;&gt;&lt;a href=&quot;#什么是机器学习&quot; class=&quot;headerlink&quot; title=&quot;什么是机器学习&quot;&gt;&lt;/a&gt;什么是机器学习&lt;/h1&gt;&lt;p&gt;filed of study that gives computers the ability to
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>关于报文压缩方法的探究</title>
    <link href="http://yoohannah.github.io/post/knowledge/compressMethod.html"/>
    <id>http://yoohannah.github.io/post/knowledge/compressMethod.html</id>
    <published>2024-03-03T10:16:37.000Z</published>
    <updated>2024-09-01T03:26:27.567Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题发现"><a href="#问题发现" class="headerlink" title="问题发现"></a>问题发现</h1><p>项目中需要对大数据量请求时间进行缩短优化的工作，优化过程中发现，浏览器响应报文压缩方法为br的情况会比gzip的时间要长11-13s，具体表现如下</p><p>服务端响应用时45s</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YmZmZTIyZmEzZWRkZDQ2OGZmODc5YmM5ZmJkMGM0ZGRfUGF4OE1qUElncThDQXd6SkpqVWFNY3g1MDNTcXBTdUlfVG9rZW46TW5namJPWnZ1b2F2MWZ4VFRQUmNuVXRnbk9oXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>但是浏览器<strong>等</strong>服务端返回却花了58s</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=OWNkYzA0ODEyYTlmMmE3ZTQ4OGM2MTc3ZDAwZTY2MzZfS3VBYVlKNDcwWTgxSklXSTRqQVdkcW1UZHd6NWR4STJfVG9rZW46Tm80M2I4Smd2b0pmamV4QkhGdWMxU3JXbmxlXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NTBiZTE2NDk3ZDg1YWFmYTQ0OTM3ODYwNGZhZjIzODlfOEtIaGNvbXc4NXhDbWNHbG1oWmtXSXVaWTBKa2tRNmFfVG9rZW46RUhlV2J1UWRqb3JUN094WWRoMWNCaE5ibmJoXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>这样浏览器就会比服务器响应<strong>多等</strong>了58-45= <strong>13s</strong>，不是很正常</p><p>现在直接拿浏览器请求的cUrl 发起请求</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ODcyYjM3NTk3MjMxYzRiNzUyYzY3MDI3ZGIyY2Y1MmFfaEJFVDNmUHFxUXlzckgxUTV5dXZ5cFZBZUhpN1Jpck5fVG9rZW46QkVpV2JrWVBlb05kYlh4R0NnNmNyQWtHbncyXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ZDU4ZDI1YjUzOWFmYTZkOWU0Y2U5NGJiOTJhZGMxODBfN3lDakIwSklNVnRMbmxCc2JaZkgzYzRLbzIwQW9RUThfVG9rZW46SzdCT2JVekpYb3VwcWd4VjM4SGNMcDBJbmZkXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NmQ2NjE1NDk2M2NlNzMyNDkyNDgzNWE5ZDY4Yzk1YzFfWEZFVDVDZVpjSVVQMjkzbHRqZk96TFhpVDAxcGxYYktfVG9rZW46TXJiZGJCOG9zb1N4eFp4WUFlRmMwRjJobkpkXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>可以看到非浏览器请求的响应使用了gzip压缩，总用时48s, 服务端用时46s, 耗时差2s</p><p>可见使用gzip压缩算法耗时是远优于br压缩的</p><h1 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h1><p>想办法禁用掉br压缩方法</p><ol><li>指定service Mesh压缩方法</li></ol><p>第一步，检查服务集群是否开启了service mesh，开启后指定才有效</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NDQ0OGQ2OWUxZDJlNGViNTJkMDMyY2I1M2Q0YjJkOWJfcms4d0dMb0ZSSnlJYk9Nb2pVWVl4a1dDMlJwellPNTVfVG9rZW46QWdNNmJXU1gzb2ljUGZ4S1ZzUWNJTUVhbjJyXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>第二步，直接在【通用流量平台-&gt;稳定性管理】指定压缩方法</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YmQwYjNiODQ2YTQ2MDM1Nzg5OGJjN2I1YzE3M2Y3NzNfM2pRbTJvOTRVblpFWDg1V3FTeUlyVkRBUWZkZ2NLT2NfVG9rZW46VlVvZWJ4NGU3bzFDd2d4blpab2M1OHdibjNkXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>Service mesh 在指定压缩方法后，会对所有请求按指定的压缩算法进行压缩，不管content-length 大小，也不管上游是否已经指定了其他压缩方法，简单粗暴，适合快速解决问题</p><ol><li>TLB + 项目配置</li></ol><p>该方法是在探究原因过程中发现，过程比较曲折，需要排查修改两个地方，着急解决问题不适宜</p><ol><li>确认下自己的服务是否为node服务且有使用koa-compress插件(<strong>注意排查框架是否有默认注入</strong>)，需要将br 压缩算法关闭，具体关闭形式可能因框架不同配置姿势不同，但可以参考下插件<a href="https://github.com/koajs/compress" target="_blank" rel="noopener">官方配置</a></li><li>关闭TLB 路由Ngnix默认br 压缩算法配置，禁止使用br算法</li></ol><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=MjE0NjZiZDAwOWViMmJmYjgwYjgzZmRhMWU5OGZmNzdfQUtKenJndjJZMmQySXdvdFlyRUFoeFVPNWZGSzRFSEtfVG9rZW46Q05TdmJMQml0b0NFQkd4aWx0bmNnYUZEbkZoXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>虽然复杂，但是方案会比方法一更合理一些</p><h2 id="为什么不在发起请求时直接更改accept-encoding？"><a href="#为什么不在发起请求时直接更改accept-encoding？" class="headerlink" title="为什么不在发起请求时直接更改accept-encoding？"></a>为什么不在发起请求时直接更改accept-encoding？</h2><p>解决这个问题的另一条途径就是从源头，请求发起端就去掉相关br的设置，也就是更改accept-encoding, 让它不包含br，如果客户端不支持br 压缩，那请求响应自然是不能使用br 压缩的，但是天有不测风云，accept-encoding 是一个不能通过代码去修改的请求报文(<a href="https://developer.mozilla.org/zh-CN/docs/Glossary/Forbidden_header_name" target="_blank" rel="noopener">详见</a>)，所以这条路是行不通的。</p><h1 id="这到底是怎么回事？"><a href="#这到底是怎么回事？" class="headerlink" title="这到底是怎么回事？"></a>这到底是怎么回事？</h1><p>虽然使用方法一可以快速彻底的解决掉问题，但是不应用方法一时，可以发现的一个明显问题就是不同请求的压缩方法不同，而且存在不使用压缩方法的情况，这就激起了作者尘封已久的好奇心，到底是谁在指定content-encoding呢？</p><p>接下来就需要看一下从服务端到客户端，到底是哪个环节在决定content-encoding</p><h2 id="Koa-compress"><a href="#Koa-compress" class="headerlink" title="Koa-compress"></a>Koa-compress</h2><p>鉴于本人node服务项目基于ACE1.X构建，在搜索代码进行排查时，并没有在配置文件中搜到相关的配置，重新查阅框架文档的时候，才注意到框架有进行<a href="https://iesfe.bytedance.net/ace-v1/fullstack/basic/middleware/#compress" target="_blank" rel="noopener">默认注入</a>，这就从服务端源头找到了一个会更改content-encoding的地方，俗话说，灯下黑，不过如此。</p><p>既然有使用koa-compress, 而且<a href="https://github.com/koajs/compress/tree/master/lib" target="_blank" rel="noopener">源码</a>不是很复杂，那就简单探索下它的压缩原理</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YTgyZTg5MmY1NWUyMTYzNGQ1NzUxZTBiM2EzYjk4N2ZfdGRzZ3lxQW1iVTdER21JYUxzQm9iWGFGbjFlSnA4bERfVG9rZW46SUVBMGJmaWJKb2xGQkh4U0JXM2NVYmVBbkNMXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>查看源码可知，当content-length大于1024b时，会根据Accept-encoding进行压缩</p><p>在Accept-Encoding值是’gzip, deflate, br’情况下</p><p>压缩方法的选择逻辑就是accept-encoding有br 会优先使用br，如果br被禁用就使用gzip</p><p>由于默认注入时，没有指定压缩阈值，所以当我们的请求数据过大, 大于1024b时，自然就会触发koa-compress进行br压缩，也就是说上面问题的出现，罪魁祸首就是koa-compress</p><p>但是当数据量小于1024b时，又会出现br，甚至不进行压缩又是怎么回事呢？</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NTk5ZjMxMTIwOTgwMTc3YzY5MjRmMjRkYjMyNDdlOGRfMHA4SlJNbDdaalBzQ1dWSXhuQXNJcXZJQTFjV2U3b0NfVG9rZW46VHBDSGJDNWZ0b2VxUW14cnFJWWNXa0ZnbkdnXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ZDIyZTAwZjdkYmI1YTg1OWY3OGFlOTI4MzFhOWVmNzdfMmFlZGZ4S25DekNnUzhSZTB4Z2NDUVY3dVpZMWs5SFpfVG9rZW46VmV1V2JlNnZzb2hHald4M0RGTWNMYk1hbk1nXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><h3 id="whisle插曲"><a href="#whisle插曲" class="headerlink" title="whisle插曲"></a>whisle插曲</h3><p>在排查过程中，相同条件请求，在本地开启whistle代理，通过域名进行本地访问，出现了响应始终是gzip 的情况，这对于大于1024b的响应就不对了，按上面koa-compress逻辑，应该是br才对</p><p>经过在http\://localhost:8899/#network 抓包，可以发现whistle给本地服务的请求报文accept-encoding是不带br的</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=OWVkMWNjYzMwZDE2N2ExMjNmNzFkOTk2NTgyM2U4YWJfZ1BYSnFNUGNZVkpvaGVRamZaenp0b2hKZHFqOEt2TU1fVG9rZW46UWxDRmIwT1Vqb3ViY2R4VFQwcGNDMDlwbnNiXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>经过与whistle开发者请教(<a href="https://github.com/avwo/whistle/issues/950" target="_blank" rel="noopener">issue</a>)，whistle确实会篡改我们的报文，把accept-encoding中的br 去掉，这样就实现了响应始终是gzip压缩的效果，因此，在本地的测试推荐大家直接使用localhost访问，避免代理的干扰</p><p>以下在本地进行的测试也均是在关闭代理情况下进行</p><h2 id="TLB"><a href="#TLB" class="headerlink" title="TLB"></a>TLB</h2><p>根据请求响应链路，响应从node服务返回后，会依次经过Mesh, TLB然后到浏览器</p><p>由于mesh 在不指定压缩算法的情况下是<strong>不参与</strong>压缩的，所以对于小于1024的数据压缩，矛头指向了TLB</p><p>在开始验证前，先来了解下TLB的压缩原理<a href="https://bytedance.feishu.cn/docx/CgO6dfGYOo86eYxILLPcMc2MnRc" target="_blank" rel="noopener">TLB压缩问题oncall排查手册</a></p><p>文中对我们比较重要的信息是这部分</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YjZmMDE3ZmJjNzYxNThjZjk5Mzc2MDBlNmVkYjk4YzRfODVpZm9jSDFKUnUwUUJzZ2hVbnIyZEJoa3lZZWo4Z2ZfVG9rZW46QVFRTWJpRXJSb0dKTHF4d25qY2NaaHpTblJkXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>文中配置与tlb同学确认后就是默认配置，这样对于我们验证就有了参照物</p><p>在关掉koa-compress 的br 压缩后，我进行了如下实验</p><ol><li>构造响应不同content-length的接口</li><li>分别通过本地localhost 访问，域名访问，以及关掉tlb 的br 压缩后再通过域名访问以上接口（保证经过tlb）</li></ol><p>得到如下结果（no表示不压缩）</p><table><thead><tr><th style="text-align:left">content-length</th><th style="text-align:left">localhost:3000</th><th style="text-align:left">域名访问</th><th style="text-align:left">tlb 设置 brotli = off</th></tr></thead><tbody><tr><td style="text-align:left">117</td><td style="text-align:left">no</td><td style="text-align:left">no</td><td style="text-align:left">no</td></tr><tr><td style="text-align:left">152</td><td style="text-align:left">no</td><td style="text-align:left">br</td><td style="text-align:left">no</td></tr><tr><td style="text-align:left">204</td><td style="text-align:left">no</td><td style="text-align:left">br</td><td style="text-align:left">gzip</td></tr><tr><td style="text-align:left">958</td><td style="text-align:left">no</td><td style="text-align:left">br</td><td style="text-align:left">gzip</td></tr><tr><td style="text-align:left">1208</td><td style="text-align:left">gzip</td><td style="text-align:left">gzip</td><td style="text-align:left">gzip</td></tr></tbody></table><p>从koa-compress 压缩原理我们可以知道从服务端响应的数据，大于1024采用gzip，小于则不压缩</p><p>所以本地访问是符合预期的</p><p>经过域名访问，我们可以看到小于1024大于150的响应被用br进行压缩了, 符合br 大于150就压缩</p><p>当把tlb 上nginx的br开启指令关掉，我们可以看到小于1024大于200的响应被用gzip压缩了，符合gzip 大于200就压缩的逻辑</p><p>再看大于1024的最后一行，当服务端已经指定content-encoding的时候，tlb 是不会进行压缩的，会沿用上游指定压缩算法</p><p>综上看来，<strong>TLB 会在上游响应未指定content-encoding的时候进行小于1M响应数据的压缩, 默认大于150b时会使用br压缩，大于200b且禁用br情况下才会使用gzip，如果上游指定了content-encoding, 就沿用上游压缩算法</strong></p><p>至此，响应报文的content-encoding 来源我们搞清楚了，接下来回到解决办法一，验证下service mesh指定压缩方法后报文变化</p><h3 id="集群插曲"><a href="#集群插曲" class="headerlink" title="集群插曲"></a>集群插曲</h3><p>虽然<a href="https://bytedance.feishu.cn/docx/CgO6dfGYOo86eYxILLPcMc2MnRc" target="_blank" rel="noopener">文档</a>中指令是默认指令，但不并是<strong>所有</strong>TLB集群的默认Ngnix 配置，如果出现了与上述结论异常的情况，需要邀请TLB 的同学帮忙查一下域名依赖的<strong>TLB 集群</strong>是否就是文档中的默认配置（因为只有TLB同学有权限可以查）</p><p>比如，相同600B请求，Boe 环境是br压缩，但是线上则变成了gzip</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ZjFjMTkwMTg2NzkzNDA3MDZmOTZlNGEzMGYzOTc2OGVfdFY3ZUhMN0tIU2lFdTRuaDFDbzl6bWNOTEtDUEwyRWtfVG9rZW46RERKdmI0azFPbzJQdjd4TkpNQ2NDd2JobmVkXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YzE1YWJjZTNjZWNhNDA4NDk0ODNjNjg0MTNlMGFlMTRfVmJ1VVA0M1pMZm5hQ0hqcDJQOVVwd3lwZUFlUm5rUHpfVG9rZW46VTVoeGJlNXhsb3g2SWN4SXBZbmNFakxGbmtBXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>按上面的结论，服务器不会对小于1024的请求进行压缩，经过tlb 默认配置会使用br，boe 环境是正常的，线上是不正常的，经过排查发现，线上tlb 依赖的<strong>集群默认</strong>配置没有开启br ，所以再走默认配置会进行gzip压缩</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=MzQzNDk5NGQyMDc0YTE4NzA1MGU5YzJkN2ZlOGM2MDlfNGtDdVNGYTUxMTdBUUR2em9aS1lpcERXN3FsNFFqRkhfVG9rZW46R2VlZWJ0TTU0b2VxcWN4OXNtM2MyQ0hibmZkXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YzUzZGYyNDkyOTE4YjQxZGVhMWU3ZDIyZmNlYWYwNjNfdzNvWUtFT0U4amcyeXdTT3U5TE51UlJoVFlPS1pFTDVfVG9rZW46SUZPY2JtamJ6b0RmQ014YWtjdmM2UWJSbjBlXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><h3 id="Cloud-IDE"><a href="#Cloud-IDE" class="headerlink" title="Cloud IDE"></a>Cloud IDE</h3><p>这里需要注意一点的是，上面我们在发现小于1024的压缩算法异常时，访问的是cloud IDE 上启动项目后帮我们生成的域名，我们在本地请求接口是没有进行压缩的，也就是说cloud IDE生成的域名是有经过TLB的，而且其集群默认开启了br压缩</p><h2 id="Service-Mesh"><a href="#Service-Mesh" class="headerlink" title="Service Mesh"></a>Service Mesh</h2><p>实验条件(复现问题)：</p><p>TLB nginx 不禁用br</p><p>不禁用koa=compress的br压缩算法</p><table><thead><tr><th style="text-align:left">content-length</th><th style="text-align:left">localhost:3000</th><th style="text-align:left">域名访问</th><th style="text-align:left">域名访问</th></tr></thead><tbody><tr><td style="text-align:left">117</td><td style="text-align:left">no</td><td style="text-align:left">no</td><td style="text-align:left">gzip</td></tr><tr><td style="text-align:left">152</td><td style="text-align:left">no</td><td style="text-align:left">br</td><td style="text-align:left">gzip</td></tr><tr><td style="text-align:left">204</td><td style="text-align:left">no</td><td style="text-align:left">br</td><td style="text-align:left">gzip</td></tr><tr><td style="text-align:left">958</td><td style="text-align:left">no</td><td style="text-align:left">br</td><td style="text-align:left">gzip</td></tr><tr><td style="text-align:left">1208</td><td style="text-align:left">br</td><td style="text-align:left">br</td><td style="text-align:left">gzip</td></tr></tbody></table><p>我们从浏览器发起请求</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=M2IyNDRhOTRhNDk3Yzg3ZWMxOWY2NWQ1NWQzYjYzZDNfWWVyY2toZjFxWDJqRlE4aGtOM25BRE5XQTU3cEpjVGNfVG9rZW46VlhJSmJDOUhtb01GREp4UzJHSmNzaTdzbkpiXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>在最后一个中间件打印响应头，说明服务器没有参与数据压缩 (可以通过设置priority让中间件在最后一个执行)</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YTJlNTA3NzA4ZTA2YjcxZjE1ZDNjMmE5ZjEzYWU1YTFfcFlUVGhlMHFyb2JwQ1JGNVRvTklaMWd1WDJoSGg2ektfVG9rZW46Wk4wMWIyUFhDb2Z6UXV4dGVUS2NqSXprbklkXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>然后通过监听端口报文</p><p>tcpdump -i eth0 port 3000 -nn</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=MzAwZDkxZjUxNWQ1YWUwNGZkNzQyZmY3ZTA5MjgwNDhfYWM5TEZTZWZvQXpRTEpoT2xOdGZRU1FISmZZUFZwSFFfVG9rZW46WGdPdWJwdzZMb2ZTd1Z4NzRPRWNvOFdSbkVjXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>基本上通过上述表现我们基本上是可以判断是mesh 进行了压缩</p><p>但是，我们现在监听的是3000配置端口(其他服务监听实例输出的端口)</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NjRjYTJiYTI1NzBmMWRlOGYzNDMxOTQ2Y2Q3MmNkYzBfMGtXMzc2c3NVQW9jUmVoNXZoV0RQVHhGOW5YZ2JqemFfVG9rZW46UGE2T2JqVjVJb2JnTDl4NXdJbGNZSG9sbjFjXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>如果3000端口吐出来的是经过了mesh的话，那通信的结构应该是这样</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NTc5NDRmMzRjOGY5MzkwZTQ3MTY0NGNhNjhlNzBiN2FfYjViaDYyRkNLVXdSZk9WeDkwS3ZYcnJGYVllZG0zOXJfVG9rZW46WHJjU2JVbHY0b2l1alJ4eVlZdWNrUzNHbkh6XzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p><strong>往深了想一下，上面的判断逻辑并不是非常精确</strong></p><ol><li>node 最后吐出来的数据的header 可能跟我们上面在最后一个中间件打印的header并不同，也就是说我们在最后一个中间件打印的header 并不是最终实例吐出数据的header，有一些 header 是会在最后吐数据的时候装的</li><li>Gzip 的请求头真的是mesh 加上去的吗？实例和mesh 之间不会还有其他服务？</li></ol><p>要解决上面两个疑问，就要想办法去抓取一下mesh 接收的数据，也就是服务吐给mesh的数据</p><h3 id="抓取mesh-socket"><a href="#抓取mesh-socket" class="headerlink" title="抓取mesh socket"></a>抓取mesh socket</h3><p>当给服务开启mesh 服务时，mesh 会给环境注入一些<a href="https://bytedance.feishu.cn/wiki/wikcnNBQTrQvvto4XpAtlgDtbvh" target="_blank" rel="noopener">环境变量</a></p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=MGQyNDk2YzM4Y2ZkNTcyMTVhOGQ2ZGQ4NThlNzMyODNfaUlEV3htRTNEZVRCWEZxVXhZR0JMVEd3dTBLQ1dDUUxfVG9rZW46SWN4cWJWdHZib2JLaEN4STY4VmM1RnRObktjXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ZGNiZjlhY2U5NDkzZjI5NjYwN2NkNGRiZWY5MDIxNjVfRmNwb1VDVFRVRWZ6bjRKWksxZlEwd2lFb2w3SlVxREVfVG9rZW46WndZWGI0aGg3bzFJaUp4ZVBzUGNxWmtyblhnXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>其中SERVICE_MESH_HTTP_EGRESS_ADDR 这个变量对应的地址就是服务交给mesh 转发的数据</p><p>即服务会往这个地址吐数据，然后再由mesh从这里转发再吐出去</p><p>那我们接下来就要想办法去读这个socket</p><p><a href="https://plantegg.github.io/2018/01/01/%E9%80%9A%E8%BF%87tcpdump%E5%AF%B9Unix%20Socket%20%E8%BF%9B%E8%A1%8C%E6%8A%93%E5%8C%85%E8%A7%A3%E6%9E%90/" target="_blank" rel="noopener">通过tcpdump对Unix Domain Socket 进行抓包解析</a></p><p>当我打算用curl 命令去执行相关方法时，却发现没有相应地址的socket</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=MTBlNWU4ZTVhNGUxZmFhNmY4NzBhMTRhMmQxYzk2ODZfVlgzRHdpZGVGbTllQnBXaVZZNVlyaTFyajRyOTBXYVdfVG9rZW46UGE3dmJIZGJlb25YVHJ4OUFaOWNaWFlGbmxUXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>ok，拉mesh 同学onCall 说这种情况是因为服务器和mesh之间不是用的uds通信，用的ip PORT通信</p><p><a href="https://bytedance.feishu.cn/wiki/wikcn4bvZsBkZMpUVC2WQ0lUzPg#OqPeFE" target="_blank" rel="noopener">ByteMesh HTTP 出流量接入</a></p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YTk1YzA0YjJmNmYxODc4ZDcwMjcxMDY2MzY3MTg1OWJfcVVsa2M1WUFxN3dtelJnQzJTbHJZNTI3cVpjWGtya3JfVG9rZW46SHJUemJRV2xwbzFrdWx4QWRDSWN1NEVvblZoXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><h3 id="抓取PORT-9507"><a href="#抓取PORT-9507" class="headerlink" title="抓取PORT 9507"></a>抓取PORT 9507</h3><p>&#x20;那我现在需要找到MESH_EGRESS_PORT具体是什么</p><p>无论是通过打印环境变量</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NTM3NTkyNGJhZmIxOWVhNTcyZmFkODhhMDJmZmFmNzlfcXk2dkRFZ3E3SUtKWVFVTkQ4ZkR2c3ZVNUw4VDBZS3dfVG9rZW46UmN3QWJ0Y0l2b1lqT2d4MWhnbGNScUJnbm1iXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>还是通过 cat /proc/\${pid}/environ 查看配置文件，以及通过查看监听端口</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ZTkxMWI0YTIxYzJkOWI4NzgxNjdlNzg1N2Q0MmU2MDdfSU1MRnNDRjFLdDNya0t6bWFoMzB0Yk5uREhlSjVZVkJfVG9rZW46SlpVZ2IwR0pVbzlSbnp4RkpoQ2NtbWVSbkJoXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>基本都确定lookback通信的port 是9507</p><p>Ok 那我们再回到用tcpdump 抓包的方式,会发现什么也抓不到</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ZTA2ZGY0ZmY5MTA0YWRmZDUwM2Y4ZWRmYzllMmUxNTdfMW9zdGE2bVp0cWMyWnpJYnhnSUNyYXZwQW16VXRISW1fVG9rZW46TE5URmJFY0g1b3ZyYkx4SkRlVmNJWFJWbkdjXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>陷入死胡同, 那就是说没有数据包经过mesh 接收数据的端口</p><h3 id="重新认识Service-Mesh"><a href="#重新认识Service-Mesh" class="headerlink" title="重新认识Service Mesh"></a>重新认识Service Mesh</h3><h4 id="入流量"><a href="#入流量" class="headerlink" title="入流量"></a>入流量</h4><p>我们之前是通过入流量开启压缩算法的</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ODJjMTdiYmU4MjExZmJiMGFmYjlkYzYyZDM5NTg1NTNfeDNjR2dwYm9neHR6OVNhOGs5eTVWMXhibkg5TWIzVE5fVG9rZW46UFFvdmJieDBtb2tiMUV4ZURmaWMxVGI1blhnXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>入流量在整个通信链路中的作用是这样的</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=MzYwYjFhOTE5YWUyM2M1MjU0NGU1NTIwODQ0NTJlNTJfTVcxUFZTcHpGM2U2a1YyUHJ2cHZJdkZ0NUNkbm5nc3BfVG9rZW46STFERGJzY2dXb3dRVGV4WExWbWNLQXVvbnVEXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>&#x20;所以现在需要抓取的是入流量的端口<a href="https://bytedance.feishu.cn/wiki/wikcntxkGyIyWhfQ2ZZiqCmOj4c" target="_blank" rel="noopener">ByteMesh WebSocket &amp; HTTP/1.1 &amp; HTTP/2协议接入约定</a></p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NmY1NDM1ODcyNDZiNDJhMjk3YTIxMjEyODJlMTIzNDNfVnlvM1hRMEVwY0RzRW0xYXFXR3hjUTdlWUNBNkowclhfVG9rZW46R2d6T2I3ZURjb0l3NEd4VHNsYmNzMnpubmRkXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>需要找到MESH_INGRESS_PORT 通过查看pid 下面 environ 文件可以看到port 为3000，也就是配置端口</p><p>然后尝试监听 <a href="https://www.cnblogs.com/zgq123456/articles/10251860.html" target="_blank" rel="noopener">https://www.cnblogs.com/zgq123456/articles/10251860.html</a></p><p>tcpdump -i any -A -s 0 ‘tcp port 3000 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)’</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NTk1NjI5ZTgzMjBlZjQ0MmY3MjNkZTM2OWI0NzRmZTBfQ1ZJM3JCcFhvamFaOGhrZXNGT0w2MUd6cVFRcnY5d2RfVG9rZW46R2tKTGJQRmlob2JqSjh4dWFLYWM1QmtjbmdkXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=NGU2ZWI0MzMzN2MxYWIwNjU0NDgzMTc1NTc2MmEyNWZfTDdvSmpVNk9xbXFpQmJFTFBNbTdsV3ZLZXRQa29JcVpfVG9rZW46WGp2NmJCeUhJbzlGMUl4UDFEZWNjTlpzbnhiXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>这一次看到了报文的整个变化过程如上两图</p><h4 id="出流量"><a href="#出流量" class="headerlink" title="出流量"></a>出流量</h4><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=MGQ3YjQ2NGZhZDU2NzY0MTRkNmRlZDAxN2FlNzRjODlfNVJIOW11d1cyWlFNZ1JYQWVMZ2t2WWw5dWg3VENlTDFfVG9rZW46WXlVa2J4R1Fsb1Jva0F4RktMZGNjWW5WbnNmXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=MGQyOGI1OGFhNjlmNDlhZThkZWJjZWY1ZjVmMDNlMThfeUxHQ0w2anc5Zjc4MTU4RUlKOW1qS2NTYWJoUFlrRkNfVG9rZW46V2Y0S2JCVHZ1b2Nndml4TTB2a2NvSUtDbjhnXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>通过给服务开启出流量代理，可以看到两种通信地址</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YjIxMDQzZjNjNTE5ZTEyYTcxMjU4NTY1NTRkMWRmZDFfRmZBRWYwc2RnT0xMUkVrZ01DNmw1NmNhUjJ0QWxUNmVfVG9rZW46Vk5BbWJzVHR5b3JnUVh4SjYwS2NSREUwbkxnXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>SERVICE_MESH_EGRESS_ADDR 即如果node 跟下游服务通信会走dsl 通信</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=OTg1NmYwMDdmNTJjNjk2MTNkNTVkYWM4M2MwYmIzYTJfZVR5VFFxNXNGM2REaXppZkpwQ1BlOWpranA3S2RRWnlfVG9rZW46STl1Y2JUUEhjb2FwcjJ4VVA3c2M1U2JIbkllXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>MESH_EGRESS_PORT 即如果node 发起http 请求会通过这个端口与mesh 进行http 通信，过程同上面入流量过程</p><h5 id="看一下UDS报文长啥样"><a href="#看一下UDS报文长啥样" class="headerlink" title="看一下UDS报文长啥样"></a>看一下UDS报文长啥样</h5><p>还是参考这篇<a href="https://plantegg.github.io/2018/01/01/%E9%80%9A%E8%BF%87tcpdump%E5%AF%B9Unix%20Socket%20%E8%BF%9B%E8%A1%8C%E6%8A%93%E5%8C%85%E8%A7%A3%E6%9E%90/" target="_blank" rel="noopener">文章</a>的方法</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=OTExN2NmOGE1ZDQ2MmU4ODllMzdmZWUxNzE0MjNlY2JfZ2hua29rcnN3WnFKSXY5SDZrWmViZ0t5U0RIdTBFZ1VfVG9rZW46QkhyWGJjZ2JRbzJDajN4V1ZtaGN6TXZYbmFiXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><ol><li>为方便后续指令执行，切到rpc.egress.sock所在文件夹，</li></ol><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ZTM0YTFmNTRkOTQwMzY2ZWUyMzdlODA4MGViYzlkNGNfWVQ2Y3FWRk5LVU93Y2xmWGEzeUU3V1pwYWd4aHlCOVpfVG9rZW46T252V2JVRGs3b29sSUh4dzRNN2NrSWNLbnFmXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=MGE2ZDE0ZmYxMjA1ODU1MWQyN2RhNjc5YjUzZWJmYzFfQ2w0eGpCN3F4SHFDUTROdjFZWGtqeDkwb042YW5NbTZfVG9rZW46R3B3SWJQbm9Tb3lvN2V4T0kxOWNnWHozbk9nXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><ol><li>将给到rpc.egress.sock 的数据转发到 8089</li></ol><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YmY1YTlkYTI3ZWFhZGM0NDZlMWIzYzM1YzExN2NjMzdfa0NISWFuZDEyeHVqR281ZzJybWRzdE55V2lsb2FPUEdfVG9rZW46UmNtQ2JZeUdob3AwVWt4SEpJWWNWQ1c1blVlXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><ol><li>用curl 发起请求，并用tcpdump 对8089进行抓包</li></ol><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=OTljZjM4MjdmYjRhZmFmZmJlZmE4M2ZkNjU5NDYyYWFfcUQ5QXc1cEdwMGNpZmxTdngxVG5ZaUV2VVFoZW1rWXlfVG9rZW46QlZkbGJUR0tOb2ZCVnJ4bkdGM2NnVUlKbnpoXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>注意使用curl –-unix-socket /rpc.egress.sock 时 如果不支持–-unix-socket 参数，需要使用apt-get 升级curl 版本，如无法升级，可能是linux 版本不再维护，可尝试替换基础镜像(指定高版本linux 的)进行部署后再测试 虽然位于rpc.egress.sock 所在文件夹下执行，但是前面的/ 不能省</p><p>先用tcpdump -i any -netvv port 8089 看看能不能</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=ZDYzMGQxYTI3OWRjZTljYjZiMmE4ZjkxYjIzMWRkY2Ffd0lOelN3Sk9COFc0TjRhSWhxamxqNmZSTGVleFNEampfVG9rZW46SGo0U2I3MjBUb2hxRUt4SnZMVmM0aGJxbjRlXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><p>加上-A -s , ===&gt; tcpdump -i any -A -s 0 -netvv port 8089 看看具体报文</p><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=N2MxNTE1ZjliYTE4ZDNhYzUzNTVmMzk3NjBmODg4MGVfc0hxdFdkTjJJRU04QVMwbURUVWNzSGZ0a1BOaDZrZDZfVG9rZW46Wk15S2J3WTZqb2RMZmp4UVBFTGNmaDdhblRmXzE3MDcyMDIyODI6MTcwNzIwNTg4Ml9WNA" alt></p><h1 id="知识收获"><a href="#知识收获" class="headerlink" title="知识收获"></a>知识收获</h1><h2 id="cUrl"><a href="#cUrl" class="headerlink" title="cUrl"></a>cUrl</h2><p>cUrl <a href="https://curl.se/docs/manual.html" target="_blank" rel="noopener">命令相关参数</a></p><p>-v/–verbose 用于打印更多信息，包括发送的请求信息</p><p>-o /dev/null 把输出写到该文件中，保留远程文件的文件名</p><p>-w ‘%{size_download}\n’ 获取下载大小</p><p>--unix-socket 测试socket 地址，注意要求curl 版本7.50+，如果webshell 不支持，需要考虑更换tce基础镜像</p><h2 id="常用linux命令"><a href="#常用linux命令" class="headerlink" title="常用linux命令"></a>常用linux命令</h2><h3 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a>tcpdump</h3><p>tcpdump -i eth0 port 3000 -nn</p><p>tcpdump -i eth0 -nn -vv</p><p>tcpdump -i lo -nn -vv</p><p><a href="https://www.cnblogs.com/zgq123456/articles/10251860.html" target="_blank" rel="noopener">https://www.cnblogs.com/zgq123456/articles/10251860.html</a></p><h3 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h3><p>lsof -i | grep LISTEN</p><p>ps -le</p><p>ps -ef | grep node</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>apt/apt-get update</p><p>apt/apt-get install 包名</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;问题发现&quot;&gt;&lt;a href=&quot;#问题发现&quot; class=&quot;headerlink&quot; title=&quot;问题发现&quot;&gt;&lt;/a&gt;问题发现&lt;/h1&gt;&lt;p&gt;项目中需要对大数据量请求时间进行缩短优化的工作，优化过程中发现，浏览器响应报文压缩方法为br的情况会比gzip的时间要长11
      
    
    </summary>
    
    
      <category term="knowledge" scheme="http://yoohannah.github.io/tags/knowledge/"/>
    
  </entry>
  
  <entry>
    <title>历史记录功能设计</title>
    <link href="http://yoohannah.github.io/post/knowledge/historySearchDesign.html"/>
    <id>http://yoohannah.github.io/post/knowledge/historySearchDesign.html</id>
    <published>2024-03-03T07:17:37.000Z</published>
    <updated>2024-09-01T03:26:27.570Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>根据用户反馈，查询条件多个时，想要重新看一下上次的查询结果，操作比较繁琐，希望可以有历史查询的功能，将最近查询的n次记录可以找到，方便回溯问题</p><h1 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h1><h2 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h2><p>在用户点击查询按钮的时候，将当前页面链接调接口保存起来，查询时链接会携带查询条件</p><h1 id="后端"><a href="#后端" class="headerlink" title="后端"></a>后端</h1><h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><p>&#x20;历史记录需要跟用户身份做绑定，当前天级uv可达75人，不适宜用tcc或者wcc平台进行数据存储</p><p>&#x20;所以需要申请资源进行数据存储</p><p><strong>容量</strong></p><p>&#x20;一个连接大小按照500Byte算，如果只保存最近10条记录，那么一个用户需要5000b ==&gt; 5kb</p><p>目前平台用户数以1000为底计算,一开始平台会需要 5kb * 1000 ==&gt;5000kb ==&gt; 5mb</p><p>(目前纯个人用户有530，加上以部门为单位申请的权限，各部门人数不确定)</p><p>假设半年后用户量翻倍那么存储空间需要增加一倍也就是10MB</p><p><strong>负载</strong></p><p>目前平台日pv 350,日uv 50, 大致计算一个用户一天会访问页面7次，四舍五入假设1天会进行10次查询</p><p>1个用户1天会进行10次数据库读写</p><p>那整个平台1天平均会进行500次读写，高峰假设1000次读写(75四舍五入)</p><p>平均 500 * 500 /(3600*24) ~~ 0.003kb/s 高峰1000*500/(3600*24) ~~~0.006kb/s</p><p>很低</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>本来想如果数据库有数组的话，表结构就是用户id + 记录数组；</p><p>没有的话，我现在想了两种方案，</p><p>一个就是用字符串存这个数组，用户id + 记录数组字符串形式，相当于更新时要先获得这个字符串，转成数组后，看有没有10条，没有的话直接push,有的话，把时间最早的那条删除，push进数组，再转成字符串更新数据库，这样缺点就是展示的时候也得字符串转数组一下；</p><p>另一种就是用户id只和一条记录存在一起，不用一个字符串存整个10条记录，更新的时候我去拿数据的时候拿整个用户id所有的，超过10条的话就用数据库删除方法把时间早的删除了，再存进去最新的</p><p>看起来都挺麻烦</p><p>而且在实际接入数据库的过程中，还要手动执行命令行产生model相关文件</p><p>通过调研公司存储系统的各种方式，觉得redis可以更好的解决存储问题，redis支持List类型存储，</p><p>而且LPUSH, LPOP,EXPIRE方法可以很好的帮助实现数据存取更新缓存等问题,省了数据库建表等过程</p><h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>redis可以很好的支持数据删除，在更新数据的时候重新设置过期时间即可保证删除不活跃用户的记录</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>申请redis服务，用户工号做redis的key值，key值的value即用户的查询历史记录list,</p><p>写接口: 查记录，更新记录</p><p>前端在点击查询的时候调接口更新记录</p><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://bytedance.feishu.cn/wiki/wikcnfEUcTwW8A3bUUQNtqUlsUd" target="_blank" rel="noopener">存储系统对比 （草稿）Storage System Comparision（Draft）</a> #</p><p><a href="https://bytedance.feishu.cn/wiki/wikcnKKISdh4ftbAj6FG24gAwCb" target="_blank" rel="noopener">数据结构与命令一览 List of data structure and commands</a> #</p><p><a href="https://redis.io/commands" target="_blank" rel="noopener">https://redis.io/commands</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;根据用户反馈，查询条件多个时，想要重新看一下上次的查询结果，操作比较繁琐，希望可以有历史查询的功能，将最近查询的n次记录可以找到，方便回溯问
      
    
    </summary>
    
    
      <category term="knowledge" scheme="http://yoohannah.github.io/tags/knowledge/"/>
    
  </entry>
  
  <entry>
    <title>Mobx 运行机制深入研究</title>
    <link href="http://yoohannah.github.io/post/knowledge/mobxlearn.html"/>
    <id>http://yoohannah.github.io/post/knowledge/mobxlearn.html</id>
    <published>2024-03-03T07:17:37.000Z</published>
    <updated>2024-09-01T03:26:27.572Z</updated>
    
    <content type="html"><![CDATA[<h1 id="追踪原理"><a href="#追踪原理" class="headerlink" title="追踪原理"></a><strong>追踪原理</strong></h1><p><a href="https://cn.mobx.js.org/best/react.html" target="_blank" rel="noopener">官方文档</a></p><p>MobX 会对在执行 <strong>跟踪函数 期间</strong> 读取的任何现有的<strong>可观察属性</strong>做出反应</p><p>“<strong>读取</strong>” 是对象属性的间接引用，可以用过 . (例如 user.name) 或者 [] (例如 user[‘name’]) 的形式完成。</p><p>“<strong>追踪函数</strong>” 是 <strong>computed 表达式、observer 组件的 render() 方法和 when、reaction 和 autorun 的第一个入参函数。</strong></p><p>“<strong>过程(during)</strong>” 意味着只追踪那些在函数执行时被读取的 observable 。这些值是否由追踪函数直接或间接使用并不重要。</p><p>换句话说，MobX 不会对其作出反应:</p><p>从 observable 获取的值，但是在追踪函数之外</p><p>在异步调用的代码块中读取的 observable</p><p>Mobx 5 以下 MobX 不会追踪还不存在的索引或者对象属性(当使用 observable 映射(map)时除外)。</p><p>所以建议总是使用 .length 来检查保护基于数组索引的访问。</p><p>所有数组的索引分配都可以检测到，但前提条件必须是提供的索引小于数组长度。</p><h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a><strong>核心概念</strong></h2><p>追踪属性访问，而不是值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">let message = observable(&#123;</span><br><span class="line">    title: &quot;Foo&quot;,</span><br><span class="line">    author: &#123;</span><br><span class="line">        name: &quot;Michel&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    likes: [</span><br><span class="line">        &quot;John&quot;, &quot;Sara&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p><img src="https://bytedance.larkoffice.com/space/api/box/stream/download/asynccode/?code=YjI2YjAxNTdhOWZkMmM1ZjFkOThlOTRhM2RlMWJkYjdfcnliUm9PSXdJWFZseExRcFdxNDhNaHNUcEh4dURwQ0pfVG9rZW46Ym94Y250QmJzT2ZWZkh3QzZVd05mNjlWSExmXzE3MDcxOTA3Mzk6MTcwNzE5NDMzOV9WNA" alt></p><p>mobx会追踪箭头有没有变化</p><p>如果箭头发生变化，就会执行追踪函数</p><h1 id="使用注意"><a href="#使用注意" class="headerlink" title="使用注意"></a><strong>使用注意</strong></h1><h2 id="处理数据时"><a href="#处理数据时" class="headerlink" title="处理数据时"></a><strong>处理数据时</strong></h2><p>1.更改没有被obserable的箭头，追踪函数不执行</p><p>2.追踪函数里使用间接引用指向obserable属性，追踪函数不执行</p><p>3.对新增的属性，可以使用set,get实现obserable</p><p>4.在异步代码中访问的obserable属性，不会引起追踪函数执行</p><pre><code>1.更改没有被obserable的箭头，追踪函数不执行autorun(() =&gt; {    console.log(message.title)})message = observable({ title: &quot;Bar&quot; }) //指向message的箭头没有被obervableautorun(() =&gt; {    message.likes;//箭头没变，又没有访问数组里面的属性})message.likes.push(&quot;Jennifer&quot;);2.追踪函数里使用间接引用指向obserable属性，追踪函数不执行var title = message.title;autorun(() =&gt; {    console.log(title) //访问箭头没有变，还是指向老值的位置})message.title = &quot;Bar&quot; //箭头改了，但autorun里没有用到const author = message.author;autorun(() =&gt; {    console.log(author.name) })message.author.name = &quot;Sara&quot;;//会执行跟踪函数，autorun里有访问name属性，这里指向name值得箭头改了message.author = { name: &quot;John&quot; };//不会执行，没有访问author属性的箭头正确使用A:autorun(() =&gt; {    console.log(message.author.name)})message.author.name = &quot;Sara&quot;;message.author = { name: &quot;John&quot; };B:function upperCaseAuthorName(author) {    const baseName = author.name;    return baseName.toUpperCase();}autorun(() =&gt; {    console.log(upperCaseAuthorName(message.author))})message.author.name = &quot;Chesterton&quot;3.异步const message = observable({ title: &quot;hello&quot; })autorun(() =&gt; {    console.log(message) //会执行两次，因为console.log是异步的，请确保始终传递不变数据 ( immutable data ) 或防御副本给 console.log。})message.title = &quot;Hello world&quot;autorun(() =&gt; {    setTimeout(        () =&gt; console.log(message.likes.join(&quot;, &quot;)), //异步执行，访问原始数据打印一次        10    )})message.likes.push(&quot;Jennifer&quot;);//不会引起autorun执行4.MobX 5 可以追踪还不存在的属性autorun(() =&gt; {    console.log(message.postDate)})message.postDate = new Date()</code></pre><h2 id="组件使用时"><a href="#组件使用时" class="headerlink" title="组件使用时"></a><strong>组件使用时</strong></h2><h3 id="子组件问题"><a href="#子组件问题" class="headerlink" title="子组件问题"></a><strong>子组件问题</strong></h3><p><strong>MobX 只会为数据是直接通过 render 存取的 observer 组件进行数据追踪</strong></p><p>所以当需要将数据传递给子组件时，要保证子组件也是一个obserable组件，可以做出反应</p><p>解决办法：</p><p>1.将子组件使用obserable函数处理</p><p>它用 mobx.autorun 包装了组件的 render 函数以确保任何组件渲染中使用的数据变化时都可以强制刷新组件</p><p>2.使用mobx-react的Obserable组件包裹子组件</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">方法一：将子组件使用obserable函数处理</span><br><span class="line"><span class="keyword">const</span> MyComponent = observer(<span class="function">(<span class="params">&#123; message &#125;</span>) =&gt;</span></span><br><span class="line">    &lt;SomeContainer</span><br><span class="line">        title = &#123;() =&gt; &lt;TitleRenderer message=&#123;message&#125; /&gt;&#125;</span><br><span class="line">    /&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">const</span> TitleRenderer = observer(<span class="function">(<span class="params">&#123; message &#125;</span>) =&gt;</span></span><br><span class="line">    &lt;div&gt;&#123;message.title&#125;&lt;<span class="regexp">/div&gt;&#125;</span></span><br><span class="line"><span class="regexp">)</span></span><br><span class="line"><span class="regexp">message.title = "Bar"</span></span><br><span class="line"><span class="regexp">方法二：使用mobx-react的Obserable组件包裹子组件</span></span><br><span class="line"><span class="regexp">const MyComponent = (&#123; message &#125;) =&gt;</span></span><br><span class="line"><span class="regexp">    &lt;SomeContainer</span></span><br><span class="line"><span class="regexp">        title = &#123;() =&gt;</span></span><br><span class="line"><span class="regexp">            &lt;Observer&gt;</span></span><br><span class="line"><span class="regexp">                &#123;() =&gt; &lt;div&gt;&#123;message.title&#125;&lt;/</span>div&gt;&#125;</span><br><span class="line">            &lt;<span class="regexp">/Observer&gt;</span></span><br><span class="line"><span class="regexp">        &#125;</span></span><br><span class="line"><span class="regexp">    /</span>&gt;</span><br><span class="line">message.title = <span class="string">"Bar"</span></span><br></pre></td></tr></table></figure><h3 id="避免在本地字段中缓存-observable"><a href="#避免在本地字段中缓存-observable" class="headerlink" title="避免在本地字段中缓存 observable"></a><strong>避免在本地字段中缓存 observable</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@observer class MyComponent extends React.component &#123;</span><br><span class="line">    author;</span><br><span class="line">    constructor(props) &#123;</span><br><span class="line">        super(props)</span><br><span class="line">        this.author = props.message.author;//message.author发生变化时不会引起render</span><br><span class="line">    &#125;</span><br><span class="line">    render() &#123;</span><br><span class="line">        return &lt;div&gt;&#123;this.author.name&#125;&lt;/div&gt; //.name可以引起render</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>优化，使用计算属性，或者在render函数中进行间接引用</p><pre><code>@observer class MyComponent extends React.component {    @computed get author() {        return this.props.message.author    }</code></pre><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>1.从性能上考虑，越晚进行间接引用越好</p><p>2.数组里面的是对象而不是字符串，那么对于发生在某个具体的对象中发生的变化，渲染数组的父组件将不会重新渲染</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">const Message = observer((&#123; message &#125;) =&gt;</span><br><span class="line">    &lt;div&gt;</span><br><span class="line">        &#123;message.title&#125;</span><br><span class="line">        &lt;Author author=&#123; message.author &#125; /&gt;</span><br><span class="line">        &lt;Likes likes=&#123; message.likes &#125; /&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">)</span><br><span class="line">const Author = observer((&#123; author &#125;) =&gt;</span><br><span class="line">    &lt;span&gt;&#123;author.name&#125;&lt;/span&gt;</span><br><span class="line">)</span><br><span class="line">const Likes = observer((&#123; likes &#125;) =&gt;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">        &#123;likes.map(like =&gt;</span><br><span class="line">            &lt;li&gt;&#123;like&#125;&lt;/li&gt;</span><br><span class="line">        )&#125;</span><br><span class="line">    &lt;/ul&gt;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">变化</th><th style="text-align:left">重新渲染组件</th></tr></thead><tbody><tr><td style="text-align:left">message.title = “Bar”</td><td style="text-align:left">Message</td></tr><tr><td style="text-align:left">message.author.name = “Susan”</td><td style="text-align:left">Author (.author 在 Message 中进行间接引用, 但没有改变)*</td></tr><tr><td style="text-align:left">message.author = { name: “Susan”}</td><td style="text-align:left">Message, Author</td></tr><tr><td style="text-align:left">message.likes[0] = “Michel”</td><td style="text-align:left">Likes</td></tr></tbody></table><h1 id="一些-对比"><a href="#一些-对比" class="headerlink" title="一些 对比"></a>一些 对比</h1><h1 id="autorun-vs-compute"><a href="#autorun-vs-compute" class="headerlink" title="autorun vs compute"></a><strong>autorun vs compute</strong></h1><p>当使用 autorun 时，所提供的函数总是立即被触发一次，然后每次它的依赖关系改变时会再次被触发</p><p>computed(function) 创建的函数只有当它有自己的观察者时才会重新计算，否则它的值会被认为是不相关的</p><p>如果一个计算值不再被观察了，例如使用它的UI不复存在了，MobX 可以自动地将其垃圾回收。</p><p>而 autorun 中的值必须要手动清理才行</p><h1 id="autorun-vs-reaction"><a href="#autorun-vs-reaction" class="headerlink" title="autorun vs reaction"></a><strong>autorun vs reaction</strong></h1><p>reaction(() =&gt; data, (data, reaction) =&gt; { sideEffect }, options?)</p><p>它接收两个函数参数，第一个(<strong>数据</strong>函数)是用来追踪并返回数据作为第二个函数(<strong>效果</strong>函数)的输入。</p><p>传入 reaction 的第二个函数(副作用函数)当调用时会接收两个参数。</p><p>第一个参数是由 data 函数返回的值。</p><p>第二个参数是当前的 reaction，可以用来在执行期间清理 reaction</p><p>reaction 返回一个清理函数。</p><p>不同于 autorun 的是当创建时 **效果 **函数不会直接运行，只有在数据表达式首次返回一个新值后才会运行。</p><p>在执行 <strong>效果</strong>函数时访问的任何 observable 都不会被追踪。</p><p><strong>效果</strong>函数仅对<strong>数据</strong>函数中访问的数据作出反应，这可能会比实际在<strong>效果</strong>函数使用的数据要少。</p><p>此外，<strong>效果</strong> 函数只会在表达式返回的数据发生更改时触发。 换句话说: reaction需要你生产 <strong>效果</strong>函数中</p><p>所需要的东西。</p><h1 id="useObserver-vs-Observer-vs-observer"><a href="#useObserver-vs-Observer-vs-observer" class="headerlink" title="useObserver vs Observer vs observer"></a><strong>useObserver vs Observer vs observer</strong></h1><p><a href="https://juejin.im/post/6844904137167994893" target="_blank" rel="noopener">相关文档</a></p><p>1.虽然只是在返回DOM的地方使用 useObserver(), 但是，当dom中数据改变的时候，整个component都会重新render</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">function Person() &#123;</span><br><span class="line">  console.log(&apos;in useObserver&apos;);//点击按钮会触发执行</span><br><span class="line">  const person = useLocalStore(() =&gt; (&#123; name: &apos;John&apos; &#125;));</span><br><span class="line">  return useObserver(() =&gt; (</span><br><span class="line">    &lt;div&gt;</span><br><span class="line">      &#123;person.name&#125;</span><br><span class="line">      &lt;button onClick=&#123;() =&gt; (person.name = &apos;Mike&apos;)&#125;&gt;No! I am Mike&lt;/button&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">  ));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2.Observer 标签组件可以更精准的控制想要重新渲染的地方</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">export default function ObservePerson() &#123;</span><br><span class="line">    console.log(&apos;in Observer&apos;);//点击按钮不会执行</span><br><span class="line">    const person = useLocalStore(() =&gt; (&#123;name: &apos;John&apos;&#125;))</span><br><span class="line">    return (</span><br><span class="line">        &lt;div&gt;</span><br><span class="line">            The old name is: &#123;person.name&#125; //点击按钮不会更新</span><br><span class="line">            &lt;div&gt;</span><br><span class="line">                &lt;Observer&gt;&#123;() =&gt; &lt;div&gt;&#123;person.name&#125;&lt;/div&gt;&#125;&lt;/Observer&gt; //点击按钮会更新</span><br><span class="line">                &lt;button onClick=&#123;() =&gt; (person.name = &apos;Mike&apos;)&#125;&gt;</span><br><span class="line">                    I want to be Mike</span><br><span class="line">                &lt;/button&gt;</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">        &lt;/div&gt;</span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3.与useObserver相比，除了使用方法不同，目前不知道区别在哪，有时间需要探究一下</p><pre><code>const ObserverLowercasePerson: React.FC&lt;any&gt; = observer(() =&gt; {    console.log(&apos;in Observer&apos;) //点击按钮也会执行    const person = useLocalStore(() =&gt; ({name: &apos;John&apos;}));    return (        &lt;div&gt;            &lt;div&gt;The name is: {person.name}&lt;/div&gt;            &lt;button onClick={() =&gt; (person.name = &apos;Mike&apos;)}&gt;                Change name            &lt;/button&gt;        &lt;/div&gt;    )})```</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;追踪原理&quot;&gt;&lt;a href=&quot;#追踪原理&quot; class=&quot;headerlink&quot; title=&quot;追踪原理&quot;&gt;&lt;/a&gt;&lt;strong&gt;追踪原理&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://cn.mobx.js.org/best/react.ht
      
    
    </summary>
    
    
      <category term="knowledge" scheme="http://yoohannah.github.io/tags/knowledge/"/>
    
  </entry>
  
</feed>
