<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css">


  <meta name="keywords" content="machineLearning,">





  <link rel="alternate" href="/atom.xml" title="My Little World" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0">






<meta name="description" content="强化学习的主要思想不是告诉算法每个输入的正确输出是什么而是指定一个奖励函数，告诉它什么时候做的好，什么时候做的不好算法的工作是自动找出如何选择好的动作  一些概念以火星探测器为例，在其决定路线的过程中产生的几个概念  S ： 当前状态 a : 动作 S’ : 下一个状态 R : 奖励函数 teminal state : 终止状态每种路线回报通过计算路上每一步奖励乘以折现系数加和得到  policy">
<meta name="keywords" content="machineLearning">
<meta property="og:type" content="article">
<meta property="og:title" content="强化学习">
<meta property="og:url" content="http://yoohannah.github.io/post/machineLearning/ReinforcementLearning.html">
<meta property="og:site_name" content="My Little World">
<meta property="og:description" content="强化学习的主要思想不是告诉算法每个输入的正确输出是什么而是指定一个奖励函数，告诉它什么时候做的好，什么时候做的不好算法的工作是自动找出如何选择好的动作  一些概念以火星探测器为例，在其决定路线的过程中产生的几个概念  S ： 当前状态 a : 动作 S’ : 下一个状态 R : 奖励函数 teminal state : 终止状态每种路线回报通过计算路上每一步奖励乘以折现系数加和得到  policy">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/202.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/203.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/204.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/205.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/206.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/207.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/208.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/209.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/210.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/211.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/212.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/213.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/214.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/215.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/216.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/217.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/218.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/219.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/220.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/221.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/222.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/223.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/224.png">
<meta property="og:image" content="http://yoohannah.github.io/image/LLM/225.png">
<meta property="og:updated_time" content="2024-11-27T09:37:11.850Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="强化学习">
<meta name="twitter:description" content="强化学习的主要思想不是告诉算法每个输入的正确输出是什么而是指定一个奖励函数，告诉它什么时候做的好，什么时候做的不好算法的工作是自动找出如何选择好的动作  一些概念以火星探测器为例，在其决定路线的过程中产生的几个概念  S ： 当前状态 a : 动作 S’ : 下一个状态 R : 奖励函数 teminal state : 终止状态每种路线回报通过计算路上每一步奖励乘以折现系数加和得到  policy">
<meta name="twitter:image" content="http://yoohannah.github.io/image/LLM/202.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoohannah.github.io/post/machineLearning/ReinforcementLearning.html">





  <title> 强化学习 | My Little World </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">My Little World</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">learn and share</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoohannah.github.io/post/machineLearning/ReinforcementLearning.html">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="YooHannah">
    <meta itemprop="description" content>
    <meta itemprop="image" content="/psb.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="My Little World">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="My Little World" src>
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                强化学习
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2024-10-07T14:34:37+08:00">
                2024-10-07
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>强化学习的主要思想不是告诉算法每个输入的正确输出是什么<br>而是指定一个奖励函数，告诉它什么时候做的好，什么时候做的不好<br>算法的工作是自动找出如何选择好的动作</p>
<p><img src="/image/LLM/202.png" alt></p>
<h1 id="一些概念"><a href="#一些概念" class="headerlink" title="一些概念"></a>一些概念</h1><p>以火星探测器为例，在其决定路线的过程中产生的几个概念</p>
<ol>
<li>S ： 当前状态</li>
<li>a : 动作</li>
<li>S’ : 下一个状态</li>
<li>R : 奖励函数</li>
<li><p>teminal state : 终止状态<br><img src="/image/LLM/203.png" alt><br>每种路线回报通过计算路上每一步奖励乘以折现系数加和得到<br><img src="/image/LLM/204.png" alt></p>
</li>
<li><p>policy : 策略函数，根据当前的状态选择可以获得最大收益的动作</p>
</li>
</ol>
<p>A policy is a function π（s）= a  mapping from states to actions, that tells you what action a to take in a given state s.</p>
<p>The goal of reinforcement learning ===&gt;<br>Find a policy 5 that tells you what action (a = 5(s)) to take in every state (s) so as to maximize the return.</p>
<p><img src="/image/LLM/205.png" alt></p>
<h1 id="马尔科夫决策过程"><a href="#马尔科夫决策过程" class="headerlink" title="马尔科夫决策过程"></a>马尔科夫决策过程</h1><p>未来只取决于当前的名称，而不是到达当前状态之前可能发生的任何事情</p>
<p><img src="/image/LLM/206.png" alt></p>
<h1 id="状态动作回报函数-Q"><a href="#状态动作回报函数-Q" class="headerlink" title="状态动作回报函数 Q"></a>状态动作回报函数 Q</h1><p>当前状态下执行一次函数能够得到的最大回报值<br>如果能够找到最大回报值也就能知道接下来应该用什么动作</p>
<p><img src="/image/LLM/207.png" alt></p>
<p><img src="/image/LLM/208.png" alt></p>
<h1 id="贝尔曼公式"><a href="#贝尔曼公式" class="headerlink" title="贝尔曼公式"></a>贝尔曼公式</h1><p><img src="/image/LLM/209.png" alt><br><img src="/image/LLM/210.png" alt><br><img src="/image/LLM/211.png" alt></p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>面对环境随机的情况，动作实际执行过程可能存在多个可能路线，导致每次得到的最大回报值不同，因此计算当前状态最大收益时取所有路线情况的平均值进行计算<br>即使用期望回报值进行计算<br><img src="/image/LLM/212.png" alt><br><img src="/image/LLM/213.png" alt></p>
<h1 id="DQN-算法"><a href="#DQN-算法" class="headerlink" title="DQN 算法"></a>DQN 算法</h1><p>D: deep learning<br>Q: Q function<br>N: Network</p>
<p>对于连续状态值的情况，使用神经网络训练Q函数进行深度强化学习<br><img src="/image/LLM/214.png" alt><br><img src="/image/LLM/215.png" alt><br><img src="/image/LLM/216.png" alt><br>By using experience replay we avoid problematic correlations, oscillations and instabilities. In addition, experience replay also allows the agent to potentially use the same experience in multiple weight updates, which increases data efficiency.<br>通过使用经验重放，我们可以避免有问题的相关性、振荡和不稳定性。此外，经验重放还允许代理在多次权重更新中使用相同的经验，从而提高数据效率。</p>
<h2 id="优化-1"><a href="#优化-1" class="headerlink" title="优化"></a>优化</h2><h3 id="优化神经网络结构"><a href="#优化神经网络结构" class="headerlink" title="优化神经网络结构"></a>优化神经网络结构</h3><p>上面将s和a作为X 同时参与训练，最终只会得到一个动作a最大回报函数值,需要进行多次运算<br>如果仅将s作为输入，输出层产生多个a的回报值，就可以根据回报值大小选择相应的动作</p>
<p><img src="/image/LLM/217.png" alt><br><img src="/image/LLM/218.png" alt></p>
<h3 id="epsilon-greedy-policy"><a href="#epsilon-greedy-policy" class="headerlink" title="epsilon-greedy policy"></a>epsilon-greedy policy</h3><p>选择action 过程中，如果一直按Q值最大原则选择action,万一初始值特别小无法开启我们想要的第一步程序，就会导致无法进行后续的action<br>epsilon-greedy policy 方案就是找一个合适的阈值epsilon，比如说0.05,<br>95%的时间选择最大Q值action (贪婪剥削策略)<br>5%的时间选择随机选择action（探索策略）<br>这样就可以避免选到固定不符合预期的action,开放一定的窗口有可能选到其他的action<br>epsilon 大小 类似于梯度，随训练过程进行会逐渐变小，变小的过程，模型也就学会了如何选择更有可能选择符合预期的action</p>
<p><img src="/image/LLM/219.png" alt></p>
<h3 id="小批量"><a href="#小批量" class="headerlink" title="小批量"></a>小批量</h3><p>训练数据如果非常庞大，在训练过程中可能会造成时间消耗，为了提高训练速度，可以采用小批量的方式进行<br>将训练数据分成多个批次，每次迭代用不同批次数据，虽然梯度会比较嘈杂，但还是会朝着梯度下降的方向进行<br><img src="/image/LLM/220.png" alt><br><img src="/image/LLM/221.png" alt><br><img src="/image/LLM/222.png" alt><br><img src="/image/LLM/223.png" alt></p>
<h3 id="软更新"><a href="#软更新" class="headerlink" title="软更新"></a>软更新</h3><p>在更新参数过程中，每次按比例更新参数，每次仅更新部分比例的参数，可以使强化学习更好的收敛<br><img src="/image/LLM/224.png" alt></p>
<h1 id="强化学习的一些限制"><a href="#强化学习的一些限制" class="headerlink" title="强化学习的一些限制"></a>强化学习的一些限制</h1><p><img src="/image/LLM/225.png" alt></p>
<p><a href="https://github.com/kaieye/2022-Machine-Learning-Specialization/blob/main/Unsupervised%20learning%20recommenders%20reinforcement%20learning/week3/Practice%20Lab-Reinforcement%20Learning/C3_W3_A1_Assignment.ipynb" target="_blank" rel="noopener">实验练习</a></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/machineLearning/" rel="tag"># machineLearning</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/post/machineLearning/RecommenderSystem.html" rel="next" title="推荐系统">
                <i class="fa fa-chevron-left"></i> 推荐系统
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/post/machineLearning/datalabel.html" rel="prev" title="数据标注">
                数据标注 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/psb.jpg" alt="YooHannah">
          <p class="site-author-name" itemprop="name">YooHannah</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">260</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">23</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#一些概念"><span class="nav-number">1.</span> <span class="nav-text">一些概念</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#马尔科夫决策过程"><span class="nav-number">2.</span> <span class="nav-text">马尔科夫决策过程</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#状态动作回报函数-Q"><span class="nav-number">3.</span> <span class="nav-text">状态动作回报函数 Q</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#贝尔曼公式"><span class="nav-number">4.</span> <span class="nav-text">贝尔曼公式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#优化"><span class="nav-number">4.1.</span> <span class="nav-text">优化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DQN-算法"><span class="nav-number">5.</span> <span class="nav-text">DQN 算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#优化-1"><span class="nav-number">5.1.</span> <span class="nav-text">优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#优化神经网络结构"><span class="nav-number">5.1.1.</span> <span class="nav-text">优化神经网络结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#epsilon-greedy-policy"><span class="nav-number">5.1.2.</span> <span class="nav-text">epsilon-greedy policy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#小批量"><span class="nav-number">5.1.3.</span> <span class="nav-text">小批量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#软更新"><span class="nav-number">5.1.4.</span> <span class="nav-text">软更新</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#强化学习的一些限制"><span class="nav-number">6.</span> <span class="nav-text">强化学习的一些限制</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YooHannah</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/treedocument/treedocument.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	




  
  

  

  

  

  


</body>
</html>
